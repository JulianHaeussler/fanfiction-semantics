{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0add1e59",
   "metadata": {},
   "source": [
    "Documentation for the Master thesis \"Fanfiction Semantics - A Quantitative Analysis of Sensitive Topics in German Fanfiction\" by Julian Jacopo Häußler, Date of submission: September 19, 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf24f0ee",
   "metadata": {},
   "source": [
    "# 7.3 Word Embedding Model Based Sentiment Analysis B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b966b9",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "### - load libraries and read in data\n",
    "### - define sentiment clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a57699",
   "metadata": {},
   "source": [
    "# LOAD LIBRARIES AND READ IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b9d6878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from itertools import cycle\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AffinityPropagation as AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc610a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "\n",
    "path_data = r'C:\\Users\\Public\\Data\\Masterarbeit\\data_bawl'\n",
    "path_models = r'C:\\Users\\Public\\Data\\Masterarbeit\\models_3.0'\n",
    "path_pickled = r'C:\\Users\\Public\\Data\\Masterarbeit\\results\\bawl_cluster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c90c8f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load models\n",
    "\n",
    "modelPotter = KeyedVectors.load(path_models + '\\\\modelPotter2021H.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28fe7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBiss = KeyedVectors.load(path_models + '\\\\modelBiss2021H.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a4bf47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelWarriorCats = KeyedVectors.load(path_models + '\\\\modelWarriorCats2021H.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e5ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDFFF = KeyedVectors.load(path_models + '\\\\modelDFFF2021H.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e9d971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMittelerde = KeyedVectors.load(path_models + '\\\\modelMittelerde2021H.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b75c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelJackson = KeyedVectors.load(path_models + '\\\\modelJackson2021H.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6ffa37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPanem = KeyedVectors.load(path_models + '\\\\modelPanem2021H.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f41719",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPotterOriginals = KeyedVectors.load(path_models + '\\\\modelPotterOriginalsH.kv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b5cc1",
   "metadata": {},
   "source": [
    "# DEFINE SENTIMENT CLUSTERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d640b4",
   "metadata": {},
   "source": [
    "The following code blocks are taken from Brottrager et al.'s \"Character Shifts in Harry Potter Fanfictions\", the relevant Jupyter Notebook can be found under https://github.com/jbrottrager/character-shifts-HPFFS/blob/main/scripts/09_BAWLcluster.ipynb (last viewed: 2022/09/18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdacd007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BAWL with word frequency of at least 50\n",
    "\n",
    "bawl = pd.read_csv(path_data + '\\\\BAWLR_with_freqs.csv')\n",
    "bawl_words = list(bawl[(bawl[\"POTTER_FREQ\"] >= 50) \n",
    "                  & (bawl[\"BISS_FREQ\"] >= 50)\n",
    "                  & (bawl[\"WARRIORCATS_FREQ\"] >= 50)\n",
    "                  & (bawl[\"DFFF_FREQ\"] >= 50)\n",
    "                  & (bawl[\"MITTELERDE_FREQ\"] >= 50)\n",
    "                  & (bawl[\"JACKSON_FREQ\"] >= 50)\n",
    "                  & (bawl[\"PANEM_FREQ\"] >= 50)\n",
    "                  & (bawl[\"POTTERORIGINALS_FREQ\"] >= 50)][\"WORD_LOWER\"]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a394578d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abend',\n",
       " 'achten',\n",
       " 'ahnung',\n",
       " 'allein',\n",
       " 'angriff',\n",
       " 'angst',\n",
       " 'annehmen',\n",
       " 'antwort',\n",
       " 'antworten',\n",
       " 'arbeit',\n",
       " 'arbeiten',\n",
       " 'aufgabe',\n",
       " 'aufhalten',\n",
       " 'aufhören',\n",
       " 'aufnehmen',\n",
       " 'auge',\n",
       " 'baum',\n",
       " 'beben',\n",
       " 'bedeuten',\n",
       " 'beenden',\n",
       " 'befehl',\n",
       " 'befinden',\n",
       " 'befreien',\n",
       " 'begegnen',\n",
       " 'begeistern',\n",
       " 'begleiten',\n",
       " 'behandeln',\n",
       " 'behaupten',\n",
       " 'beispiel',\n",
       " 'bekennen',\n",
       " 'bekommen',\n",
       " 'bereiten',\n",
       " 'berichten',\n",
       " 'berühren',\n",
       " 'bestehen',\n",
       " 'bestimmen',\n",
       " 'besuch',\n",
       " 'besuchen',\n",
       " 'betrachten',\n",
       " 'bewegen',\n",
       " 'bewegung',\n",
       " 'beweisen',\n",
       " 'bieten',\n",
       " 'bild',\n",
       " 'bilden',\n",
       " 'bitte',\n",
       " 'bitten',\n",
       " 'bleiben',\n",
       " 'blick',\n",
       " 'blut',\n",
       " 'boden',\n",
       " 'brauchen',\n",
       " 'brechen',\n",
       " 'brennen',\n",
       " 'bruder',\n",
       " 'brust',\n",
       " 'buch',\n",
       " 'chance',\n",
       " 'dank',\n",
       " 'dauern',\n",
       " 'decke',\n",
       " 'ding',\n",
       " 'drängen',\n",
       " 'dringen',\n",
       " 'drohen',\n",
       " 'drücken',\n",
       " 'ehe',\n",
       " 'ehrlich',\n",
       " 'eindruck',\n",
       " 'einsetzen',\n",
       " 'eintreten',\n",
       " 'empfinden',\n",
       " 'ende',\n",
       " 'enden',\n",
       " 'entdecken',\n",
       " 'entfernen',\n",
       " 'entsetzt',\n",
       " 'erde',\n",
       " 'erfahren',\n",
       " 'erfüllen',\n",
       " 'ergreifen',\n",
       " 'erhalten',\n",
       " 'erheben',\n",
       " 'erinnern',\n",
       " 'erinnerung',\n",
       " 'erkennen',\n",
       " 'erlauben',\n",
       " 'erleben',\n",
       " 'erledigen',\n",
       " 'erreichen',\n",
       " 'erwarten',\n",
       " 'erzählen',\n",
       " 'essen',\n",
       " 'fahren',\n",
       " 'fall',\n",
       " 'fallen',\n",
       " 'familie',\n",
       " 'fangen',\n",
       " 'farbe',\n",
       " 'fassen',\n",
       " 'fehlen',\n",
       " 'fehler',\n",
       " 'fest',\n",
       " 'feucht',\n",
       " 'feuer',\n",
       " 'finden',\n",
       " 'flamme',\n",
       " 'fliegen',\n",
       " 'frage',\n",
       " 'fragen',\n",
       " 'freuen',\n",
       " 'freund',\n",
       " 'froh',\n",
       " 'fühlen',\n",
       " 'füllen',\n",
       " 'fürchten',\n",
       " 'gedanke',\n",
       " 'gedenken',\n",
       " 'gefahr',\n",
       " 'gefallen',\n",
       " 'gefühl',\n",
       " 'geheimnis',\n",
       " 'gehen',\n",
       " 'gehören',\n",
       " 'geist',\n",
       " 'gelingen',\n",
       " 'geschehen',\n",
       " 'geschichte',\n",
       " 'gesicht',\n",
       " 'gespräch',\n",
       " 'gewinnen',\n",
       " 'glas',\n",
       " 'glauben',\n",
       " 'glück',\n",
       " 'gras',\n",
       " 'grinsen',\n",
       " 'grund',\n",
       " 'gruppe',\n",
       " 'hängen',\n",
       " 'haus',\n",
       " 'heben',\n",
       " 'heißen',\n",
       " 'helfen',\n",
       " 'herrschen',\n",
       " 'herz',\n",
       " 'hilfe',\n",
       " 'himmel',\n",
       " 'hoffen',\n",
       " 'hoffnung',\n",
       " 'höhe',\n",
       " 'holen',\n",
       " 'junge',\n",
       " 'kampf',\n",
       " 'kämpfen',\n",
       " 'katze',\n",
       " 'kehle',\n",
       " 'kehren',\n",
       " 'kennen',\n",
       " 'kichern',\n",
       " 'kind',\n",
       " 'komisch',\n",
       " 'kommen',\n",
       " 'können',\n",
       " 'kraft',\n",
       " 'kreis',\n",
       " 'kriegen',\n",
       " 'kümmern',\n",
       " 'lächeln',\n",
       " 'lachen',\n",
       " 'lage',\n",
       " 'laufen',\n",
       " 'laune',\n",
       " 'laut',\n",
       " 'leben',\n",
       " 'legen',\n",
       " 'leiche',\n",
       " 'leid',\n",
       " 'leiden',\n",
       " 'lernen',\n",
       " 'letzte',\n",
       " 'leuchten',\n",
       " 'leute',\n",
       " 'licht',\n",
       " 'lieb',\n",
       " 'lieben',\n",
       " 'liegen',\n",
       " 'lippe',\n",
       " 'loch',\n",
       " 'lösen',\n",
       " 'luft',\n",
       " 'lüge',\n",
       " 'lust',\n",
       " 'machen',\n",
       " 'macht',\n",
       " 'magen',\n",
       " 'matt',\n",
       " 'meinen',\n",
       " 'meinung',\n",
       " 'melden',\n",
       " 'menge',\n",
       " 'miene',\n",
       " 'minute',\n",
       " 'mitte',\n",
       " 'mögen',\n",
       " 'monat',\n",
       " 'mühe',\n",
       " 'müssen',\n",
       " 'mustern',\n",
       " 'mut',\n",
       " 'mutig',\n",
       " 'mutter',\n",
       " 'nachricht',\n",
       " 'nacht',\n",
       " 'nah',\n",
       " 'nähe',\n",
       " 'name',\n",
       " 'narbe',\n",
       " 'nase',\n",
       " 'nehmen',\n",
       " 'nein',\n",
       " 'nennen',\n",
       " 'nett',\n",
       " 'nicken',\n",
       " 'niemand',\n",
       " 'nutzen',\n",
       " 'öffnen',\n",
       " 'opfer',\n",
       " 'ordnung',\n",
       " 'paar',\n",
       " 'panik',\n",
       " 'pause',\n",
       " 'plan',\n",
       " 'platz',\n",
       " 'platzen',\n",
       " 'pochen',\n",
       " 'problem',\n",
       " 'punkt',\n",
       " 'raum',\n",
       " 'rede',\n",
       " 'regen',\n",
       " 'reichen',\n",
       " 'reihe',\n",
       " 'reißen',\n",
       " 'rennen',\n",
       " 'retten',\n",
       " 'richten',\n",
       " 'rolle',\n",
       " 'rufen',\n",
       " 'ruhe',\n",
       " 'ruhig',\n",
       " 'sache',\n",
       " 'sagen',\n",
       " 'sanft',\n",
       " 'satz',\n",
       " 'schaden',\n",
       " 'schaffen',\n",
       " 'scharf',\n",
       " 'schatten',\n",
       " 'schenken',\n",
       " 'schieben',\n",
       " 'schießen',\n",
       " 'schlaf',\n",
       " 'schlafen',\n",
       " 'schlag',\n",
       " 'schlagen',\n",
       " 'schlecht',\n",
       " 'schließen',\n",
       " 'schlimm',\n",
       " 'schloss',\n",
       " 'schmerz',\n",
       " 'schnee',\n",
       " 'schreck',\n",
       " 'schrei',\n",
       " 'schreiben',\n",
       " 'schreien',\n",
       " 'schritt',\n",
       " 'schuld',\n",
       " 'schütteln',\n",
       " 'schutz',\n",
       " 'schützen',\n",
       " 'schwach',\n",
       " 'schwarz',\n",
       " 'schweben',\n",
       " 'schweigen',\n",
       " 'schwester',\n",
       " 'see',\n",
       " 'seele',\n",
       " 'sehen',\n",
       " 'seite',\n",
       " 'seltsam',\n",
       " 'senken',\n",
       " 'setzen',\n",
       " 'seufzen',\n",
       " 'sicherheit',\n",
       " 'sichern',\n",
       " 'sieben',\n",
       " 'sinken',\n",
       " 'sinn',\n",
       " 'sitzen',\n",
       " 'sohn',\n",
       " 'sollen',\n",
       " 'sonnen',\n",
       " 'sorge',\n",
       " 'sorgen',\n",
       " 'spaß',\n",
       " 'spiel',\n",
       " 'spielen',\n",
       " 'sprechen',\n",
       " 'spüren',\n",
       " 'stark',\n",
       " 'starren',\n",
       " 'stechen',\n",
       " 'stehen',\n",
       " 'stehlen',\n",
       " 'steigen',\n",
       " 'stein',\n",
       " 'stelle',\n",
       " 'stellen',\n",
       " 'sterben',\n",
       " 'stern',\n",
       " 'stimmung',\n",
       " 'stolpern',\n",
       " 'stolz',\n",
       " 'stören',\n",
       " 'stoßen',\n",
       " 'strahlen',\n",
       " 'streichen',\n",
       " 'stumm',\n",
       " 'stunde',\n",
       " 'stürzen',\n",
       " 'suche',\n",
       " 'suchen',\n",
       " 'tag',\n",
       " 'tauchen',\n",
       " 'teil',\n",
       " 'teilen',\n",
       " 'thema',\n",
       " 'tiefe',\n",
       " 'tier',\n",
       " 'tod',\n",
       " 'ton',\n",
       " 'tot',\n",
       " 'töten',\n",
       " 'tragen',\n",
       " 'träne',\n",
       " 'traum',\n",
       " 'traurig',\n",
       " 'treffen',\n",
       " 'treiben',\n",
       " 'treten',\n",
       " 'triefen',\n",
       " 'trinken',\n",
       " 'tropfen',\n",
       " 'übel',\n",
       " 'üben',\n",
       " 'überlegen',\n",
       " 'überzeugen',\n",
       " 'vater',\n",
       " 'verändern',\n",
       " 'verbieten',\n",
       " 'verdienen',\n",
       " 'verfolgen',\n",
       " 'vergehen',\n",
       " 'vergessen',\n",
       " 'verlangen',\n",
       " 'verlassen',\n",
       " 'verlegen',\n",
       " 'verletzen',\n",
       " 'verlieren',\n",
       " 'vermuten',\n",
       " 'verraten',\n",
       " 'versetzen',\n",
       " 'versichern',\n",
       " 'verstehen',\n",
       " 'versuch',\n",
       " 'vertrauen',\n",
       " 'verwandeln',\n",
       " 'vogel',\n",
       " 'vorkommen',\n",
       " 'vorstellen',\n",
       " 'wache',\n",
       " 'wachsen',\n",
       " 'wagen',\n",
       " 'wahl',\n",
       " 'wahren',\n",
       " 'wahrheit',\n",
       " 'wald',\n",
       " 'wand',\n",
       " 'wandern',\n",
       " 'wange',\n",
       " 'warm',\n",
       " 'warnen',\n",
       " 'wasser',\n",
       " 'weg',\n",
       " 'weichen',\n",
       " 'weise',\n",
       " 'weisen',\n",
       " 'weit',\n",
       " 'welt',\n",
       " 'wenden',\n",
       " 'wenig',\n",
       " 'werfen',\n",
       " 'wert',\n",
       " 'wind',\n",
       " 'wirken',\n",
       " 'wissen',\n",
       " 'woche',\n",
       " 'wolle',\n",
       " 'wollen',\n",
       " 'wort',\n",
       " 'wunsch',\n",
       " 'wünschen',\n",
       " 'zählen',\n",
       " 'zahn',\n",
       " 'zeigen',\n",
       " 'zerstören',\n",
       " 'ziehen',\n",
       " 'ziel',\n",
       " 'zittern',\n",
       " 'zögern',\n",
       " 'zorn',\n",
       " 'zunge',\n",
       " 'zwingen']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bawl_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cdd38f",
   "metadata": {},
   "source": [
    "## 1. POTTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14285330",
   "metadata": {},
   "source": [
    "### 1. High Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f7e1e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['sommer', 'zuhause', 'ferien'], 5: ['wahrheit', 'freund', 'glück', 'freude', 'lieben', 'freiheit', 'liebe'], 4: ['lebendig', 'heilung', 'gesund'], 2: ['erdbeere', 'sex', 'küssen'], 0: ['idylle', 'harmonie', 'frieden', 'kreativ', 'sonne', 'paradies'], 1: ['super', 'lachen', 'prima']}\n",
      "a: ITEMS ['idylle', 'harmonie', 'frieden', 'kreativ', 'sonne', 'paradies']\n",
      "a: AVG SIMILARITY 0.1797077973683675\n",
      "a: MEAN VALENCE 2.5882352941176467\n",
      "a: MEAN VALENCE STD 0.6100949839784297\n",
      "a: MEAN AROUSAL 2.221132897603486\n",
      "a: MEAN AROUSAL STD 1.226280752186\n",
      "a: SUGGESTION VALUE 2.8917228420018213\n",
      "b: ITEMS ['super', 'lachen', 'prima']\n",
      "b: AVG SIMILARITY 0.3320593883593877\n",
      "b: MEAN VALENCE 2.615686274509804\n",
      "b: MEAN VALENCE STD 0.5583570833575552\n",
      "b: MEAN AROUSAL 2.920760233918129\n",
      "b: MEAN AROUSAL STD 1.2482180075712401\n",
      "b: SUGGESTION VALUE 2.766015954357159\n",
      "c: ITEMS ['erdbeere', 'sex', 'küssen']\n",
      "c: AVG SIMILARITY 0.26240985095500946\n",
      "c: MEAN VALENCE 2.572549019607843\n",
      "c: MEAN VALENCE STD 0.6767196715932847\n",
      "c: MEAN AROUSAL 3.443968253968254\n",
      "c: MEAN AROUSAL STD 1.2557930337095815\n",
      "c: SUGGESTION VALUE 2.4984316527071457\n",
      "d: ITEMS ['sommer', 'zuhause', 'ferien']\n",
      "d: AVG SIMILARITY 0.45478816827138263\n",
      "d: MEAN VALENCE 2.533333333333333\n",
      "d: MEAN VALENCE STD 0.6372505868936233\n",
      "d: MEAN AROUSAL 2.132897603485839\n",
      "d: MEAN AROUSAL STD 1.2109033341254436\n",
      "d: SUGGESTION VALUE 2.721426942642429\n",
      "e: ITEMS ['lebendig', 'heilung', 'gesund']\n",
      "e: AVG SIMILARITY 0.20409755781292915\n",
      "e: MEAN VALENCE 2.6\n",
      "e: MEAN VALENCE STD 0.6154659264981074\n",
      "e: MEAN AROUSAL 2.346691893131522\n",
      "e: MEAN AROUSAL STD 1.0475733962881169\n",
      "e: SUGGESTION VALUE 2.5336146922008207\n",
      "f: ITEMS ['wahrheit', 'freund', 'glück', 'freude', 'lieben', 'freiheit', 'liebe']\n",
      "f: AVG SIMILARITY 0.22200666721688495\n",
      "f: MEAN VALENCE 2.683193277310924\n",
      "f: MEAN VALENCE STD 0.5627173749060066\n",
      "f: MEAN AROUSAL 3.2422821760283056\n",
      "f: MEAN AROUSAL STD 1.2807238024230247\n",
      "f: SUGGESTION VALUE 3.296108213779738\n",
      "1 ['wahrheit', 'freund', 'glück', 'freude', 'lieben', 'freiheit', 'liebe']\n",
      "2 ['idylle', 'harmonie', 'frieden', 'kreativ', 'sonne', 'paradies']\n",
      "3 ['super', 'lachen', 'prima']\n",
      "4 ['sommer', 'zuhause', 'ferien']\n",
      "5 ['lebendig', 'heilung', 'gesund']\n",
      "6 ['erdbeere', 'sex', 'küssen']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = 2\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"POTTER_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] >= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "top_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"POTTER_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelPotter.key_to_index[word] for word in high_valence_words]\n",
    "valence_word_vectors = [modelPotter.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation on PCA\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = high_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "\n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_valence_words)[class_members])))\n",
    "    for member1 in np.array(high_valence_words)[class_members]:\n",
    "        for member2 in np.array(high_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelPotter.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))                        \n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_val_Potter = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_val_Potter.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_val_Potter, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63db1f9c",
   "metadata": {},
   "source": [
    "### 2. Low Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b15a8a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['krieg', 'nazi', 'weltkrieg', 'massaker'], 1: ['alptraum', 'folter', 'mord', 'qual', 'gewalt'], 3: ['foltern', 'tod', 'töten', 'morden', 'tyrann', 'angst', 'zerstören', 'tot', 'unmensch', 'hassen'], 2: ['pest'], 5: ['tumor', 'tote', 'gift'], 4: ['bombe'], 6: ['erzfeind']}\n",
      "a: ITEMS ['krieg', 'nazi', 'weltkrieg', 'massaker']\n",
      "a: AVG SIMILARITY 0.3960659106572469\n",
      "a: MEAN VALENCE -2.855882352941176\n",
      "a: MEAN VALENCE STD 0.4074742589879832\n",
      "a: MEAN AROUSAL 4.617063492063492\n",
      "a: MEAN AROUSAL STD 0.6965397001468534\n",
      "a: SUGGESTION VALUE 3.4574759305665195\n",
      "b: ITEMS ['alptraum', 'folter', 'mord', 'qual', 'gewalt']\n",
      "b: AVG SIMILARITY 0.35311315655708314\n",
      "b: MEAN VALENCE -2.7599999999999993\n",
      "b: MEAN VALENCE STD 0.5646860082200025\n",
      "b: MEAN AROUSAL 4.4300260455059215\n",
      "b: MEAN AROUSAL STD 0.764019512744706\n",
      "b: SUGGESTION VALUE 3.252510582797069\n",
      "c: ITEMS ['pest']\n",
      "c: MEAN VALENCE -2.8\n",
      "c: MEAN VALENCE STD 0.4216370213557839\n",
      "c: MEAN AROUSAL 4.0\n",
      "c: MEAN AROUSAL STD 1.0846522890932808\n",
      "c: SUGGESTION VALUE 0\n",
      "d: ITEMS ['foltern', 'tod', 'töten', 'morden', 'tyrann', 'angst', 'zerstören', 'tot', 'unmensch', 'hassen']\n",
      "d: AVG SIMILARITY 0.29542187932464814\n",
      "d: MEAN VALENCE -2.623529411764706\n",
      "d: MEAN VALENCE STD 0.6997625001409038\n",
      "d: MEAN AROUSAL 4.199355742296919\n",
      "d: MEAN AROUSAL STD 0.9872394267570245\n",
      "d: SUGGESTION VALUE 3.6148246973806595\n",
      "e: ITEMS ['bombe']\n",
      "e: MEAN VALENCE -2.5\n",
      "e: MEAN VALENCE STD 0.60697698\n",
      "e: MEAN AROUSAL 4.0\n",
      "e: MEAN AROUSAL STD 1.0846522890932808\n",
      "e: SUGGESTION VALUE 0\n",
      "f: ITEMS ['tumor', 'tote', 'gift']\n",
      "f: AVG SIMILARITY 0.29380687574545544\n",
      "f: MEAN VALENCE -2.6\n",
      "f: MEAN VALENCE STD 0.6591844166555495\n",
      "f: MEAN AROUSAL 4.2254901960784315\n",
      "f: MEAN AROUSAL STD 0.9138362726496302\n",
      "f: SUGGESTION VALUE 2.586854824203953\n",
      "g: ITEMS ['erzfeind']\n",
      "g: MEAN VALENCE -2.5\n",
      "g: MEAN VALENCE STD 0.5270462766947299\n",
      "g: MEAN AROUSAL 3.6666666666666665\n",
      "g: MEAN AROUSAL STD 1.3284223283101428\n",
      "g: SUGGESTION VALUE 0\n",
      "1 ['foltern', 'tod', 'töten', 'morden', 'tyrann', 'angst', 'zerstören', 'tot', 'unmensch', 'hassen']\n",
      "2 ['krieg', 'nazi', 'weltkrieg', 'massaker']\n",
      "3 ['alptraum', 'folter', 'mord', 'qual', 'gewalt']\n",
      "4 ['tumor', 'tote', 'gift']\n",
      "5 ['pest']\n",
      "6 ['bombe']\n",
      "7 ['erzfeind']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = -2\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"POTTER_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] <= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"POTTER_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelPotter.key_to_index[word] for word in low_valence_words]\n",
    "valence_word_vectors = [modelPotter.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = low_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "    \n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_valence_words)[class_members])))\n",
    "    for member1 in np.array(low_valence_words)[class_members]:\n",
    "        for member2 in np.array(low_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelPotter.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "    \n",
    "low_val_Potter = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_val_Potter.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_val_Potter, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbaae53",
   "metadata": {},
   "source": [
    "### 3. High Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24cd70d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['trauma', 'tumor', 'alptraum'], 3: ['schrei', 'alarm', 'erdbeben'], 6: ['furcht', 'atemnot', 'ekstase', 'panik'], 1: ['erotik'], 2: ['hassen', 'foltern', 'brutal', 'folter'], 7: ['mord', 'attentat'], 5: ['terror', 'unheil', 'bestie', 'krieg', 'massaker', 'weltkrieg', 'nazi'], 4: ['notfall']}\n",
      "a: ITEMS ['trauma', 'tumor', 'alptraum']\n",
      "a: AVG SIMILARITY 0.35044728716214496\n",
      "a: MEAN VALENCE -2.5166666666666666\n",
      "a: MEAN VALENCE STD 0.6764246840112254\n",
      "a: MEAN AROUSAL 4.480392156862746\n",
      "a: MEAN AROUSAL STD 0.769331271683298\n",
      "a: SUGGESTION VALUE 4.701703398006936\n",
      "b: ITEMS ['erotik']\n",
      "b: MEAN VALENCE 2.3\n",
      "b: MEAN VALENCE STD 0.4830458915396481\n",
      "b: MEAN AROUSAL 4.4375\n",
      "b: MEAN AROUSAL STD 0.8139410298049853\n",
      "b: SUGGESTION VALUE 0\n",
      "c: ITEMS ['hassen', 'foltern', 'brutal', 'folter']\n",
      "c: AVG SIMILARITY 0.32142750918865204\n",
      "c: MEAN VALENCE -2.525\n",
      "c: MEAN VALENCE STD 0.58078709\n",
      "c: MEAN AROUSAL 4.524853801169591\n",
      "c: MEAN AROUSAL STD 0.7965188691286542\n",
      "c: SUGGESTION VALUE 4.922511558329824\n",
      "d: ITEMS ['schrei', 'alarm', 'erdbeben']\n",
      "d: AVG SIMILARITY 0.2897480974594752\n",
      "d: MEAN VALENCE -1.5666666666666667\n",
      "d: MEAN VALENCE STD 0.8156597961626068\n",
      "d: MEAN AROUSAL 4.445361770439171\n",
      "d: MEAN AROUSAL STD 0.7275520015441765\n",
      "d: SUGGESTION VALUE 4.639249175038594\n",
      "e: ITEMS ['notfall']\n",
      "e: MEAN VALENCE -1.7\n",
      "e: MEAN VALENCE STD 0.9486832980505138\n",
      "e: MEAN AROUSAL 4.529411764705882\n",
      "e: MEAN AROUSAL STD 0.7174300539794393\n",
      "e: SUGGESTION VALUE 0\n",
      "f: ITEMS ['terror', 'unheil', 'bestie', 'krieg', 'massaker', 'weltkrieg', 'nazi']\n",
      "f: AVG SIMILARITY 0.2997583995262782\n",
      "f: MEAN VALENCE -2.560504201680672\n",
      "f: MEAN VALENCE STD 0.5869294247606506\n",
      "f: MEAN AROUSAL 4.578698145925037\n",
      "f: MEAN AROUSAL STD 0.6867841263145179\n",
      "f: SUGGESTION VALUE 5.898104032603935\n",
      "g: ITEMS ['furcht', 'atemnot', 'ekstase', 'panik']\n",
      "g: AVG SIMILARITY 0.37995391587416333\n",
      "g: MEAN VALENCE -1.05\n",
      "g: MEAN VALENCE STD 0.9504692167688236\n",
      "g: MEAN AROUSAL 4.484375\n",
      "g: MEAN AROUSAL STD 0.7714954228467751\n",
      "g: SUGGESTION VALUE 4.974864690984123\n",
      "h: ITEMS ['mord', 'attentat']\n",
      "h: AVG SIMILARITY 0.4765930473804474\n",
      "h: MEAN VALENCE -2.5999999999999996\n",
      "h: MEAN VALENCE STD 0.5604214600679425\n",
      "h: MEAN AROUSAL 4.575163398692811\n",
      "h: MEAN AROUSAL STD 0.7548223650111048\n",
      "h: SUGGESTION VALUE 4.737369824371025\n",
      "1 ['terror', 'unheil', 'bestie', 'krieg', 'massaker', 'weltkrieg', 'nazi']\n",
      "2 ['furcht', 'atemnot', 'ekstase', 'panik']\n",
      "3 ['hassen', 'foltern', 'brutal', 'folter']\n",
      "4 ['mord', 'attentat']\n",
      "5 ['trauma', 'tumor', 'alptraum']\n",
      "6 ['schrei', 'alarm', 'erdbeben']\n",
      "7 ['erotik']\n",
      "8 ['notfall']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"POTTER_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] >= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "top_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"POTTER_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelPotter.key_to_index[word] for word in high_arousal_words]\n",
    "arousal_word_vectors = [modelPotter.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = high_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_arousal_words)[class_members])))\n",
    "    for member1 in np.array(high_arousal_words)[class_members]:\n",
    "        for member2 in np.array(high_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelPotter.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + sum(arousal_means) / len(arousal_means) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(high_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "\n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_arousal_Potter = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_arousal_Potter.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_arousal_Potter, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961824b7",
   "metadata": {},
   "source": [
    "### 4. Low Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ec574b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['schlaf', 'erholung', 'pause', 'friede'], 4: ['still', 'zahm', 'zaghaft', 'passiv', 'wenig'], 2: ['wiege', 'aquarium', 'beutel', 'schale', 'murmel', 'kamin'], 1: ['balsam', 'weich', 'seide', 'seife'], 3: ['buche', 'wiese', 'birke', 'linde', 'harfe', 'baum']}\n",
      "a: ITEMS ['schlaf', 'erholung', 'pause', 'friede']\n",
      "a: AVG SIMILARITY 0.29807837307453156\n",
      "a: MEAN VALENCE 1.9375\n",
      "a: MEAN VALENCE STD 0.9630955734305765\n",
      "a: MEAN AROUSAL 1.2950832964764853\n",
      "a: MEAN AROUSAL STD 0.5852768358077337\n",
      "a: SUGGESTION VALUE 2.9387516324196308\n",
      "b: ITEMS ['balsam', 'weich', 'seide', 'seife']\n",
      "b: AVG SIMILARITY 0.2760186766584714\n",
      "b: MEAN VALENCE 1.2125000000000001\n",
      "b: MEAN VALENCE STD 0.7841843774999999\n",
      "b: MEAN AROUSAL 1.4071207430340558\n",
      "b: MEAN AROUSAL STD 0.649377090719572\n",
      "b: SUGGESTION VALUE 2.697841456556106\n",
      "c: ITEMS ['wiege', 'aquarium', 'beutel', 'schale', 'murmel', 'kamin']\n",
      "c: AVG SIMILARITY 0.24265015721321107\n",
      "c: MEAN VALENCE 0.9733333333333333\n",
      "c: MEAN VALENCE STD 0.9195433433333334\n",
      "c: MEAN AROUSAL 1.4176998050682261\n",
      "c: MEAN AROUSAL STD 0.6076064552378077\n",
      "c: SUGGESTION VALUE 2.9714528900117587\n",
      "d: ITEMS ['buche', 'wiese', 'birke', 'linde', 'harfe', 'baum']\n",
      "d: AVG SIMILARITY 0.3764010310173035\n",
      "d: MEAN VALENCE 1.3666666666666665\n",
      "d: MEAN VALENCE STD 1.170081027940664\n",
      "d: MEAN AROUSAL 1.4409471390895539\n",
      "d: MEAN AROUSAL STD 0.6519100725077468\n",
      "d: SUGGESTION VALUE 3.060167117580909\n",
      "e: ITEMS ['still', 'zahm', 'zaghaft', 'passiv', 'wenig']\n",
      "e: AVG SIMILARITY 0.15949713215231895\n",
      "e: MEAN VALENCE -0.34\n",
      "e: MEAN VALENCE STD 0.732\n",
      "e: MEAN AROUSAL 1.431578947368421\n",
      "e: MEAN AROUSAL STD 0.7943591693872414\n",
      "e: SUGGESTION VALUE 2.467765721356407\n",
      "1 ['buche', 'wiese', 'birke', 'linde', 'harfe', 'baum']\n",
      "2 ['wiege', 'aquarium', 'beutel', 'schale', 'murmel', 'kamin']\n",
      "3 ['schlaf', 'erholung', 'pause', 'friede']\n",
      "4 ['balsam', 'weich', 'seide', 'seife']\n",
      "5 ['still', 'zahm', 'zaghaft', 'passiv', 'wenig']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"POTTER_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] <= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"POTTER_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelPotter.key_to_index[word] for word in low_arousal_words]\n",
    "arousal_word_vectors = [modelPotter.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = low_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_arousal_words)[class_members])))\n",
    "    for member1 in np.array(low_arousal_words)[class_members]:\n",
    "        for member2 in np.array(low_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelPotter.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + (4 - sum(arousal_means) / len(arousal_means)) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(low_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "low_arousal_Potter = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_arousal_Potter.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_arousal_Potter, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e31ad6",
   "metadata": {},
   "source": [
    "## 2. BISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e8c4b2",
   "metadata": {},
   "source": [
    "### 1. High Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90e84828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['fantasie', 'musik', 'wahrheit', 'freiheit', 'liebe'], 1: ['perfekt', 'super', 'prima', 'gesund'], 4: ['positiv', 'lebendig', 'glück', 'lachen', 'freude', 'lieben'], 2: ['freizeit', 'urlaub', 'zuhause', 'sommer', 'ferien', 'heilung'], 3: ['erdbeere', 'freund', 'sex', 'küssen']}\n",
      "a: ITEMS ['fantasie', 'musik', 'wahrheit', 'freiheit', 'liebe']\n",
      "a: AVG SIMILARITY 0.13676601890474557\n",
      "a: MEAN VALENCE 2.6\n",
      "a: MEAN VALENCE STD 0.5196579172897808\n",
      "a: MEAN AROUSAL 3.074093567251462\n",
      "a: MEAN AROUSAL STD 1.2402510632084776\n",
      "a: SUGGESTION VALUE 2.829654192160557\n",
      "b: ITEMS ['perfekt', 'super', 'prima', 'gesund']\n",
      "b: AVG SIMILARITY 0.22357503324747086\n",
      "b: MEAN VALENCE 2.575\n",
      "b: MEAN VALENCE STD 0.6275\n",
      "b: MEAN AROUSAL 2.681798245614035\n",
      "b: MEAN AROUSAL STD 1.1263849832416006\n",
      "b: SUGGESTION VALUE 2.6389552721312595\n",
      "c: ITEMS ['freizeit', 'urlaub', 'zuhause', 'sommer', 'ferien', 'heilung']\n",
      "c: AVG SIMILARITY 0.2142697848379612\n",
      "c: MEAN VALENCE 2.5083333333333333\n",
      "c: MEAN VALENCE STD 0.5758275182782525\n",
      "c: MEAN AROUSAL 2.366081154684096\n",
      "c: MEAN AROUSAL STD 1.1542732684120218\n",
      "c: SUGGESTION VALUE 2.8768846228167853\n",
      "d: ITEMS ['erdbeere', 'freund', 'sex', 'küssen']\n",
      "d: AVG SIMILARITY 0.1843169629573822\n",
      "d: MEAN VALENCE 2.5691176470588233\n",
      "d: MEAN VALENCE STD 0.6606783380718455\n",
      "d: MEAN AROUSAL 3.096134085213033\n",
      "d: MEAN AROUSAL STD 1.2241183351015559\n",
      "d: SUGGESTION VALUE 2.5437583282750698\n",
      "e: ITEMS ['positiv', 'lebendig', 'glück', 'lachen', 'freude', 'lieben']\n",
      "e: AVG SIMILARITY 0.17766964336236318\n",
      "e: MEAN VALENCE 2.5950980392156864\n",
      "e: MEAN VALENCE STD 0.6537119033254337\n",
      "e: MEAN AROUSAL 3.085294117647059\n",
      "e: MEAN AROUSAL STD 1.2657097150095449\n",
      "e: SUGGESTION VALUE 2.8397374120176435\n",
      "1 ['freizeit', 'urlaub', 'zuhause', 'sommer', 'ferien', 'heilung']\n",
      "2 ['positiv', 'lebendig', 'glück', 'lachen', 'freude', 'lieben']\n",
      "3 ['fantasie', 'musik', 'wahrheit', 'freiheit', 'liebe']\n",
      "4 ['perfekt', 'super', 'prima', 'gesund']\n",
      "5 ['erdbeere', 'freund', 'sex', 'küssen']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = 2\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"BISS_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] >= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "top_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"BISS_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelBiss.key_to_index[word] for word in high_valence_words]\n",
    "valence_word_vectors = [modelBiss.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation on PCA\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = high_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "\n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_valence_words)[class_members])))\n",
    "    for member1 in np.array(high_valence_words)[class_members]:\n",
    "        for member2 in np.array(high_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelBiss.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))                        \n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_val_Biss = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_val_Biss.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_val_Biss, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb7fff5",
   "metadata": {},
   "source": [
    "### 2. Low Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e022761d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['krieg', 'tod', 'mord', 'folter', 'strafe', 'unfall', 'grab'], 0: ['alptraum', 'angst', 'schlecht'], 2: ['foltern', 'töten', 'gewalt', 'qual', 'zerstören', 'gift', 'tot', 'hassen', 'leiche', 'leblos'], 4: ['tote', 'bombe', 'waffe', 'gefängnis'], 3: ['negativ']}\n",
      "a: ITEMS ['alptraum', 'angst', 'schlecht']\n",
      "a: AVG SIMILARITY 0.25038673480351764\n",
      "a: MEAN VALENCE -2.566666666666667\n",
      "a: MEAN VALENCE STD 0.6672204769379256\n",
      "a: MEAN AROUSAL 4.229380641145347\n",
      "a: MEAN AROUSAL STD 0.6973534324074256\n",
      "a: SUGGESTION VALUE 2.4887003392616567\n",
      "b: ITEMS ['krieg', 'tod', 'mord', 'folter', 'strafe', 'unfall', 'grab']\n",
      "b: AVG SIMILARITY 0.21646292365732647\n",
      "b: MEAN VALENCE -2.6214285714285714\n",
      "b: MEAN VALENCE STD 0.6011920502506946\n",
      "b: MEAN AROUSAL 4.21905955364602\n",
      "b: MEAN AROUSAL STD 0.837286669273281\n",
      "b: SUGGESTION VALUE 3.1472607341826158\n",
      "c: ITEMS ['foltern', 'töten', 'gewalt', 'qual', 'zerstören', 'gift', 'tot', 'hassen', 'leiche', 'leblos']\n",
      "c: AVG SIMILARITY 0.20024685232589642\n",
      "c: MEAN VALENCE -2.568529411764706\n",
      "c: MEAN VALENCE STD 0.7168033305594247\n",
      "c: MEAN AROUSAL 4.155238095238096\n",
      "c: MEAN AROUSAL STD 0.9531713666856143\n",
      "c: SUGGESTION VALUE 3.3424476857216807\n",
      "d: ITEMS ['negativ']\n",
      "d: MEAN VALENCE -2.4\n",
      "d: MEAN VALENCE STD 0.84\n",
      "d: MEAN AROUSAL 3.555555555555556\n",
      "d: MEAN AROUSAL STD 0.7838233761296743\n",
      "d: SUGGESTION VALUE 0\n",
      "e: ITEMS ['tote', 'bombe', 'waffe', 'gefängnis']\n",
      "e: AVG SIMILARITY 0.20058790345986685\n",
      "e: MEAN VALENCE -2.4286764705882353\n",
      "e: MEAN VALENCE STD 0.6918579374489386\n",
      "e: MEAN AROUSAL 3.8667993513194747\n",
      "e: MEAN AROUSAL STD 1.0323260782704193\n",
      "e: SUGGESTION VALUE 2.3549296324765128\n",
      "1 ['foltern', 'töten', 'gewalt', 'qual', 'zerstören', 'gift', 'tot', 'hassen', 'leiche', 'leblos']\n",
      "2 ['krieg', 'tod', 'mord', 'folter', 'strafe', 'unfall', 'grab']\n",
      "3 ['alptraum', 'angst', 'schlecht']\n",
      "4 ['tote', 'bombe', 'waffe', 'gefängnis']\n",
      "5 ['negativ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = -2\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"BISS_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] <= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"BISS_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelBiss.key_to_index[word] for word in low_valence_words]\n",
    "valence_word_vectors = [modelBiss.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = low_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "    \n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_valence_words)[class_members])))\n",
    "    for member1 in np.array(low_valence_words)[class_members]:\n",
    "        for member2 in np.array(low_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelBiss.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "    \n",
    "low_val_Biss = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_val_Biss.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_val_Biss, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e1418",
   "metadata": {},
   "source": [
    "### 3. High Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4d4fabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: ['tot', 'tote', 'waffe', 'unfall', 'gewalt', 'mord', 'notfall', 'krieg'], 3: ['drohung', 'sex', 'foltern', 'hassen', 'brutal', 'folter'], 0: ['geburt', 'trennung'], 2: ['panisch', 'ohrfeige', 'blutig', 'schrei'], 1: ['gefahr', 'angst', 'furcht', 'alptraum', 'panik']}\n",
      "a: ITEMS ['geburt', 'trennung']\n",
      "a: AVG SIMILARITY 0.3701315224170685\n",
      "a: MEAN VALENCE 0.09999999999999998\n",
      "a: MEAN VALENCE STD 0.9302964040252568\n",
      "a: MEAN AROUSAL 4.235294117647059\n",
      "a: MEAN AROUSAL STD 0.8272933171531047\n",
      "a: SUGGESTION VALUE 4.165390886009402\n",
      "b: ITEMS ['gefahr', 'angst', 'furcht', 'alptraum', 'panik']\n",
      "b: AVG SIMILARITY 0.3092178553342819\n",
      "b: MEAN VALENCE -2.24\n",
      "b: MEAN VALENCE STD 0.8035011257120784\n",
      "b: MEAN AROUSAL 4.458263305322129\n",
      "b: MEAN AROUSAL STD 0.636471903062702\n",
      "b: SUGGESTION VALUE 5.272330949983665\n",
      "c: ITEMS ['panisch', 'ohrfeige', 'blutig', 'schrei']\n",
      "c: AVG SIMILARITY 0.18286674345533052\n",
      "c: MEAN VALENCE -1.875\n",
      "c: MEAN VALENCE STD 0.8426136143609835\n",
      "c: MEAN AROUSAL 4.326443713450292\n",
      "c: MEAN AROUSAL STD 0.712043560436694\n",
      "c: SUGGESTION VALUE 4.615601645576087\n",
      "d: ITEMS ['drohung', 'sex', 'foltern', 'hassen', 'brutal', 'folter']\n",
      "d: AVG SIMILARITY 0.18923564106225968\n",
      "d: MEAN VALENCE -1.5999999999999999\n",
      "d: MEAN VALENCE STD 0.5678653919486448\n",
      "d: MEAN AROUSAL 4.434869854374498\n",
      "d: MEAN AROUSAL STD 0.8038459127908218\n",
      "d: SUGGESTION VALUE 5.119513212759702\n",
      "e: ITEMS ['tot', 'tote', 'waffe', 'unfall', 'gewalt', 'mord', 'notfall', 'krieg']\n",
      "e: AVG SIMILARITY 0.20444779164556945\n",
      "e: MEAN VALENCE -2.4875\n",
      "e: MEAN VALENCE STD 0.6435794167754046\n",
      "e: MEAN AROUSAL 4.343195611577964\n",
      "e: MEAN AROUSAL STD 0.7726275780881265\n",
      "e: SUGGESTION VALUE 5.577417681236168\n",
      "1 ['tot', 'tote', 'waffe', 'unfall', 'gewalt', 'mord', 'notfall', 'krieg']\n",
      "2 ['gefahr', 'angst', 'furcht', 'alptraum', 'panik']\n",
      "3 ['drohung', 'sex', 'foltern', 'hassen', 'brutal', 'folter']\n",
      "4 ['panisch', 'ohrfeige', 'blutig', 'schrei']\n",
      "5 ['geburt', 'trennung']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"BISS_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] >= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "top_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"BISS_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelBiss.key_to_index[word] for word in high_arousal_words]\n",
    "arousal_word_vectors = [modelBiss.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = high_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_arousal_words)[class_members])))\n",
    "    for member1 in np.array(high_arousal_words)[class_members]:\n",
    "        for member2 in np.array(high_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelBiss.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + sum(arousal_means) / len(arousal_means) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(high_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "\n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_arousal_Biss = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_arousal_Biss.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_arousal_Biss, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903e202",
   "metadata": {},
   "source": [
    "### 4. Low Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1729e2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['schlaf', 'weich', 'wiese', 'wenig', 'boden', 'gras', 'decke', 'garten'], 1: ['still', 'zaghaft', 'stumm'], 0: ['pause', 'friede', 'segen'], 2: ['beutel', 'schale', 'ding', 'honig', 'nudel', 'teller'], 4: ['baum', 'kamin', 'liege', 'klang', 'tanne']}\n",
      "a: ITEMS ['pause', 'friede', 'segen']\n",
      "a: AVG SIMILARITY 0.21038169662157694\n",
      "a: MEAN VALENCE 1.7166666666666668\n",
      "a: MEAN VALENCE STD 1.1520701533333333\n",
      "a: MEAN AROUSAL 1.4436507936507936\n",
      "a: MEAN AROUSAL STD 0.7749930839381302\n",
      "a: SUGGESTION VALUE 2.305685492757675\n",
      "b: ITEMS ['still', 'zaghaft', 'stumm']\n",
      "b: AVG SIMILARITY 0.21622995535532633\n",
      "b: MEAN VALENCE -0.3666666666666667\n",
      "b: MEAN VALENCE STD 0.7133333333333334\n",
      "b: MEAN AROUSAL 1.4210526315789471\n",
      "b: MEAN AROUSAL STD 0.7891388740917341\n",
      "b: SUGGESTION VALUE 2.3222402603161876\n",
      "c: ITEMS ['beutel', 'schale', 'ding', 'honig', 'nudel', 'teller']\n",
      "c: AVG SIMILARITY 0.2789863131940365\n",
      "c: MEAN VALENCE 0.8600980392156862\n",
      "c: MEAN VALENCE STD 0.840368452979658\n",
      "c: MEAN AROUSAL 1.5302899610136453\n",
      "c: MEAN AROUSAL STD 0.7400868749449655\n",
      "c: SUGGESTION VALUE 2.691728804161255\n",
      "d: ITEMS ['schlaf', 'weich', 'wiese', 'wenig', 'boden', 'gras', 'decke', 'garten']\n",
      "d: AVG SIMILARITY 0.16774383905742848\n",
      "d: MEAN VALENCE 0.9662499999999999\n",
      "d: MEAN VALENCE STD 0.9805454645014692\n",
      "d: MEAN AROUSAL 1.4698039215686274\n",
      "d: MEAN AROUSAL STD 0.6588207257504746\n",
      "d: SUGGESTION VALUE 3.0127077503685453\n",
      "e: ITEMS ['baum', 'kamin', 'liege', 'klang', 'tanne']\n",
      "e: AVG SIMILARITY 0.21336900517344476\n",
      "e: MEAN VALENCE 1.4\n",
      "e: MEAN VALENCE STD 0.9871782436086125\n",
      "e: MEAN AROUSAL 1.5410526315789475\n",
      "e: MEAN AROUSAL STD 0.7348282166751592\n",
      "e: SUGGESTION VALUE 2.472780412238259\n",
      "1 ['schlaf', 'weich', 'wiese', 'wenig', 'boden', 'gras', 'decke', 'garten']\n",
      "2 ['beutel', 'schale', 'ding', 'honig', 'nudel', 'teller']\n",
      "3 ['baum', 'kamin', 'liege', 'klang', 'tanne']\n",
      "4 ['still', 'zaghaft', 'stumm']\n",
      "5 ['pause', 'friede', 'segen']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"BISS_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] <= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"BISS_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelBiss.key_to_index[word] for word in low_arousal_words]\n",
    "arousal_word_vectors = [modelBiss.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = low_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_arousal_words)[class_members])))\n",
    "    for member1 in np.array(low_arousal_words)[class_members]:\n",
    "        for member2 in np.array(low_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelBiss.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + (4 - sum(arousal_means) / len(arousal_means)) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(low_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "low_arousal_Biss = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_arousal_Biss.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_arousal_Biss, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a51c27",
   "metadata": {},
   "source": [
    "## 3. WARRIORCATS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70d21b8",
   "metadata": {},
   "source": [
    "### 1.1 High Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bc9bb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: ['warm', 'himmel', 'blüte'], 0: ['treu', 'vertrauen', 'wahrheit', 'gesund', 'lieben'], 1: ['sieg', 'reisen', 'reise', 'genießen', 'leben', 'zuhause'], 3: ['freuen', 'gefühl', 'spaß', 'perfekt', 'super', 'glück', 'freude', 'liebe'], 4: ['lächeln', 'freund', 'lachen']}\n",
      "a: ITEMS ['treu', 'vertrauen', 'wahrheit', 'gesund', 'lieben']\n",
      "a: AVG SIMILARITY 0.18742917850613594\n",
      "a: MEAN VALENCE 2.4623529411764706\n",
      "a: MEAN VALENCE STD 0.7115240315537839\n",
      "a: MEAN AROUSAL 2.831578947368421\n",
      "a: MEAN AROUSAL STD 1.1714270441523005\n",
      "a: SUGGESTION VALUE 2.473763061245317\n",
      "b: ITEMS ['sieg', 'reisen', 'reise', 'genießen', 'leben', 'zuhause']\n",
      "b: AVG SIMILARITY 0.21451869681477548\n",
      "b: MEAN VALENCE 2.3151960784313728\n",
      "b: MEAN VALENCE STD 0.7585605537396574\n",
      "b: MEAN AROUSAL 2.7914488017429195\n",
      "b: MEAN AROUSAL STD 1.2860334867278962\n",
      "b: SUGGESTION VALUE 2.373516051115415\n",
      "c: ITEMS ['warm', 'himmel', 'blüte']\n",
      "c: AVG SIMILARITY 0.18990723292032877\n",
      "c: MEAN VALENCE 2.2566666666666664\n",
      "c: MEAN VALENCE STD 0.7234884899999999\n",
      "c: MEAN AROUSAL 1.9088888888888889\n",
      "c: MEAN AROUSAL STD 1.0695256767218821\n",
      "c: SUGGESTION VALUE 1.9946867472731455\n",
      "d: ITEMS ['freuen', 'gefühl', 'spaß', 'perfekt', 'super', 'glück', 'freude', 'liebe']\n",
      "d: AVG SIMILARITY 0.18467545389596904\n",
      "d: MEAN VALENCE 2.4816176470588234\n",
      "d: MEAN VALENCE STD 0.686261274821342\n",
      "d: MEAN AROUSAL 3.2863181237407244\n",
      "d: MEAN AROUSAL STD 1.413447504075959\n",
      "d: SUGGESTION VALUE 2.925408800396466\n",
      "e: ITEMS ['lächeln', 'freund', 'lachen']\n",
      "e: AVG SIMILARITY 0.1943353215853373\n",
      "e: MEAN VALENCE 2.5000000000000004\n",
      "e: MEAN VALENCE STD 0.6563457506443191\n",
      "e: MEAN AROUSAL 2.4143692564745196\n",
      "e: MEAN AROUSAL STD 1.1677353651290467\n",
      "e: SUGGESTION VALUE 2.3592276770605967\n",
      "1 ['freuen', 'gefühl', 'spaß', 'perfekt', 'super', 'glück', 'freude', 'liebe']\n",
      "2 ['treu', 'vertrauen', 'wahrheit', 'gesund', 'lieben']\n",
      "3 ['sieg', 'reisen', 'reise', 'genießen', 'leben', 'zuhause']\n",
      "4 ['lächeln', 'freund', 'lachen']\n",
      "5 ['warm', 'himmel', 'blüte']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = 2\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"WARRIORCATS_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] >= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "top_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"WARRIORCATS_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelWarriorCats.key_to_index[word] for word in high_valence_words]\n",
    "valence_word_vectors = [modelWarriorCats.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation on PCA\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = high_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "\n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_valence_words)[class_members])))\n",
    "    for member1 in np.array(high_valence_words)[class_members]:\n",
    "        for member2 in np.array(high_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelWarriorCats.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))                        \n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_val_WarriorCats = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_val_WarriorCats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_val_WarriorCats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc7cf1",
   "metadata": {},
   "source": [
    "### 2. Low Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e495304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['krieg', 'tote', 'zerstören', 'streit', 'stehlen'], 1: ['mord', 'tod', 'töten', 'strafe', 'verrat', 'unfall', 'schlecht', 'verlust', 'grausam', 'lüge'], 3: ['qual', 'angst', 'furcht', 'trauer'], 2: ['tot', 'leiche', 'leichnam', 'grab', 'leblos', 'einsam']}\n",
      "a: ITEMS ['krieg', 'tote', 'zerstören', 'streit', 'stehlen']\n",
      "a: AVG SIMILARITY 0.22577126920223237\n",
      "a: MEAN VALENCE -2.4858823529411764\n",
      "a: MEAN VALENCE STD 0.5927022695740826\n",
      "a: MEAN AROUSAL 4.067040149393091\n",
      "a: MEAN AROUSAL STD 0.863080592508131\n",
      "a: SUGGESTION VALUE 2.704378543118669\n",
      "b: ITEMS ['mord', 'tod', 'töten', 'strafe', 'verrat', 'unfall', 'schlecht', 'verlust', 'grausam', 'lüge']\n",
      "b: AVG SIMILARITY 0.24374271349774468\n",
      "b: MEAN VALENCE -2.42735294117647\n",
      "b: MEAN VALENCE STD 0.6963854679950113\n",
      "b: MEAN AROUSAL 4.013174603174603\n",
      "b: MEAN AROUSAL STD 0.9453614309336433\n",
      "b: SUGGESTION VALUE 3.2165948125244337\n",
      "c: ITEMS ['tot', 'leiche', 'leichnam', 'grab', 'leblos', 'einsam']\n",
      "c: AVG SIMILARITY 0.2657271149257819\n",
      "c: MEAN VALENCE -2.358333333333333\n",
      "c: MEAN VALENCE STD 0.8359502158433553\n",
      "c: MEAN AROUSAL 3.7714130096483043\n",
      "c: MEAN AROUSAL STD 1.0482665624716627\n",
      "c: SUGGESTION VALUE 2.3962387274173156\n",
      "d: ITEMS ['qual', 'angst', 'furcht', 'trauer']\n",
      "d: AVG SIMILARITY 0.35851525018612546\n",
      "d: MEAN VALENCE -2.4000000000000004\n",
      "d: MEAN VALENCE STD 0.7827177835593172\n",
      "d: MEAN AROUSAL 4.140043736792963\n",
      "d: MEAN AROUSAL STD 0.8471634171562621\n",
      "d: SUGGESTION VALUE 2.4015941694190523\n",
      "1 ['mord', 'tod', 'töten', 'strafe', 'verrat', 'unfall', 'schlecht', 'verlust', 'grausam', 'lüge']\n",
      "2 ['krieg', 'tote', 'zerstören', 'streit', 'stehlen']\n",
      "3 ['qual', 'angst', 'furcht', 'trauer']\n",
      "4 ['tot', 'leiche', 'leichnam', 'grab', 'leblos', 'einsam']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = -2\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"WARRIORCATS_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] <= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"WARRIORCATS_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelWarriorCats.key_to_index[word] for word in low_valence_words]\n",
    "valence_word_vectors = [modelWarriorCats.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = low_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "    \n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_valence_words)[class_members])))\n",
    "    for member1 in np.array(low_valence_words)[class_members]:\n",
    "        for member2 in np.array(low_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelWarriorCats.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "    \n",
    "low_val_WarriorCats = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_val_WarriorCats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_val_WarriorCats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130ee0c5",
   "metadata": {},
   "source": [
    "### 3. High Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "513c5ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: ['wucht', 'zorn', 'schreck', 'schmerz', 'panisch', 'angst', 'furcht', 'panik'], 4: ['lüge', 'leid', 'unfall', 'mord', 'krieg'], 0: ['sturm', 'scharf', 'schrei'], 1: ['leiche', 'tot', 'geburt'], 2: ['feind', 'gefahr', 'brutal'], 3: ['macht', 'tote', 'blutig']}\n",
      "a: ITEMS ['sturm', 'scharf', 'schrei']\n",
      "a: AVG SIMILARITY 0.2016271948814392\n",
      "a: MEAN VALENCE -0.5666666666666668\n",
      "a: MEAN VALENCE STD 1.1660722389296734\n",
      "a: MEAN AROUSAL 4.208771929824562\n",
      "a: MEAN AROUSAL STD 0.8045649177778761\n",
      "a: SUGGESTION VALUE 4.174203823795171\n",
      "b: ITEMS ['leiche', 'tot', 'geburt']\n",
      "b: AVG SIMILARITY 0.26984018584092456\n",
      "b: MEAN VALENCE -1.0166666666666668\n",
      "b: MEAN VALENCE STD 0.84035472\n",
      "b: MEAN AROUSAL 4.161998132586368\n",
      "b: MEAN AROUSAL STD 0.8866517010928522\n",
      "b: SUGGESTION VALUE 4.1039966578917815\n",
      "c: ITEMS ['feind', 'gefahr', 'brutal']\n",
      "c: AVG SIMILARITY 0.30015169084072113\n",
      "c: MEAN VALENCE -1.9823529411764707\n",
      "c: MEAN VALENCE STD 0.7779619537104682\n",
      "c: MEAN AROUSAL 4.352422723475356\n",
      "c: MEAN AROUSAL STD 0.8738014759221141\n",
      "c: SUGGESTION VALUE 4.374402022808312\n",
      "d: ITEMS ['macht', 'tote', 'blutig']\n",
      "d: AVG SIMILARITY 0.1928454339504242\n",
      "d: MEAN VALENCE -1.4333333333333333\n",
      "d: MEAN VALENCE STD 0.9531754060621328\n",
      "d: MEAN AROUSAL 4.2254901960784315\n",
      "d: MEAN AROUSAL STD 0.834365600483645\n",
      "d: SUGGESTION VALUE 4.148893305452275\n",
      "e: ITEMS ['lüge', 'leid', 'unfall', 'mord', 'krieg']\n",
      "e: AVG SIMILARITY 0.2412747133523226\n",
      "e: MEAN VALENCE -2.4335294117647055\n",
      "e: MEAN VALENCE STD 0.6584432977817127\n",
      "e: MEAN AROUSAL 4.295238095238095\n",
      "e: MEAN AROUSAL STD 0.7461989005190512\n",
      "e: SUGGESTION VALUE 4.837507756958806\n",
      "f: ITEMS ['wucht', 'zorn', 'schreck', 'schmerz', 'panisch', 'angst', 'furcht', 'panik']\n",
      "f: AVG SIMILARITY 0.3121784473104136\n",
      "f: MEAN VALENCE -1.7669117647058825\n",
      "f: MEAN VALENCE STD 0.9629781265987105\n",
      "f: MEAN AROUSAL 4.263019374416434\n",
      "f: MEAN AROUSAL STD 0.7519002514299091\n",
      "f: SUGGESTION VALUE 5.64875180846071\n",
      "1 ['wucht', 'zorn', 'schreck', 'schmerz', 'panisch', 'angst', 'furcht', 'panik']\n",
      "2 ['lüge', 'leid', 'unfall', 'mord', 'krieg']\n",
      "3 ['feind', 'gefahr', 'brutal']\n",
      "4 ['sturm', 'scharf', 'schrei']\n",
      "5 ['macht', 'tote', 'blutig']\n",
      "6 ['leiche', 'tot', 'geburt']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"WARRIORCATS_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] >= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "top_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"WARRIORCATS_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelWarriorCats.key_to_index[word] for word in high_arousal_words]\n",
    "arousal_word_vectors = [modelWarriorCats.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = high_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_arousal_words)[class_members])))\n",
    "    for member1 in np.array(high_arousal_words)[class_members]:\n",
    "        for member2 in np.array(high_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelWarriorCats.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + sum(arousal_means) / len(arousal_means) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(high_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "\n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_arousal_WarriorCats = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_arousal_WarriorCats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_arousal_WarriorCats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187dae74",
   "metadata": {},
   "source": [
    "### 4. Low Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96900d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['schlaf', 'weich', 'boden', 'gras', 'sand'], 4: ['still', 'stumm', 'schweigen'], 0: ['pause', 'friede', 'gesund'], 2: ['wiese', 'wenig', 'decke', 'himmel', 'milch', 'wange', 'feder', 'regnen', 'glas'], 1: ['birke', 'baum', 'ding', 'stamm', 'eiche']}\n",
      "a: ITEMS ['pause', 'friede', 'gesund']\n",
      "a: AVG SIMILARITY 0.20022520422935486\n",
      "a: MEAN VALENCE 2.0833333333333335\n",
      "a: MEAN VALENCE STD 0.8876682699999999\n",
      "a: MEAN AROUSAL 1.470843776106934\n",
      "a: MEAN AROUSAL STD 0.7329413179146852\n",
      "a: SUGGESTION VALUE 2.3111289825792305\n",
      "b: ITEMS ['birke', 'baum', 'ding', 'stamm', 'eiche']\n",
      "b: AVG SIMILARITY 0.26235354617238044\n",
      "b: MEAN VALENCE 0.9061176470588237\n",
      "b: MEAN VALENCE STD 1.0346646551043865\n",
      "b: MEAN AROUSAL 1.5757660818713448\n",
      "b: MEAN AROUSAL STD 0.7144040018168821\n",
      "b: SUGGESTION VALUE 2.5170613910359356\n",
      "c: ITEMS ['wiese', 'wenig', 'decke', 'himmel', 'milch', 'wange', 'feder', 'regnen', 'glas']\n",
      "c: AVG SIMILARITY 0.16997984631194007\n",
      "c: MEAN VALENCE 0.9777777777777779\n",
      "c: MEAN VALENCE STD 0.981738178859405\n",
      "c: MEAN AROUSAL 1.6316580667354659\n",
      "c: MEAN AROUSAL STD 0.8108604243620648\n",
      "c: SUGGESTION VALUE 2.6798595423565996\n",
      "d: ITEMS ['schlaf', 'weich', 'boden', 'gras', 'sand']\n",
      "d: AVG SIMILARITY 0.27483400851488116\n",
      "d: MEAN VALENCE 1.1192941176470588\n",
      "d: MEAN VALENCE STD 1.0330974151532288\n",
      "d: MEAN AROUSAL 1.4571812865497076\n",
      "d: MEAN AROUSAL STD 0.6190460480630045\n",
      "d: SUGGESTION VALUE 2.8060411610907883\n",
      "e: ITEMS ['still', 'stumm', 'schweigen']\n",
      "e: AVG SIMILARITY 0.28180373708407086\n",
      "e: MEAN VALENCE -0.18823529411764706\n",
      "e: MEAN VALENCE STD 1.1891125119607497\n",
      "e: MEAN AROUSAL 1.5076023391812867\n",
      "e: MEAN AROUSAL STD 0.8354968779300882\n",
      "e: SUGGESTION VALUE 2.244292819933392\n",
      "1 ['schlaf', 'weich', 'boden', 'gras', 'sand']\n",
      "2 ['wiese', 'wenig', 'decke', 'himmel', 'milch', 'wange', 'feder', 'regnen', 'glas']\n",
      "3 ['birke', 'baum', 'ding', 'stamm', 'eiche']\n",
      "4 ['pause', 'friede', 'gesund']\n",
      "5 ['still', 'stumm', 'schweigen']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"WARRIORCATS_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] <= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"WARRIORCATS_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelWarriorCats.key_to_index[word] for word in low_arousal_words]\n",
    "arousal_word_vectors = [modelWarriorCats.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = low_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_arousal_words)[class_members])))\n",
    "    for member1 in np.array(low_arousal_words)[class_members]:\n",
    "        for member2 in np.array(low_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelWarriorCats.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + (4 - sum(arousal_means) / len(arousal_means)) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(low_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "low_arousal_WarriorCats = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_arousal_WarriorCats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_arousal_WarriorCats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5227b3",
   "metadata": {},
   "source": [
    "## 4. DFFF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0f4e1a",
   "metadata": {},
   "source": [
    "### 1. High Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95d92d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['genießen', 'positiv', 'zuhause', 'wahrheit', 'küssen', 'gesund', 'lieben', 'liebe'], 0: ['spaß', 'musik', 'fantasie', 'sex', 'glück', 'freude'], 2: ['natur', 'leben', 'urlaub', 'sommer', 'lebendig', 'ferien', 'freiheit'], 1: ['perfekt', 'super', 'freund', 'lachen']}\n",
      "a: ITEMS ['spaß', 'musik', 'fantasie', 'sex', 'glück', 'freude']\n",
      "a: AVG SIMILARITY 0.15246365902324518\n",
      "a: MEAN VALENCE 2.5068627450980387\n",
      "a: MEAN VALENCE STD 0.5737877172904731\n",
      "a: MEAN AROUSAL 3.1660446049764936\n",
      "a: MEAN AROUSAL STD 1.2517520023314639\n",
      "a: SUGGESTION VALUE 2.7948213025767576\n",
      "b: ITEMS ['perfekt', 'super', 'freund', 'lachen']\n",
      "b: AVG SIMILARITY 0.15041651452581087\n",
      "b: MEAN VALENCE 2.526470588235294\n",
      "b: MEAN VALENCE STD 0.6619063968950484\n",
      "b: MEAN AROUSAL 2.850657894736842\n",
      "b: MEAN AROUSAL STD 1.2136001103827632\n",
      "b: SUGGESTION VALUE 2.4492216416096033\n",
      "c: ITEMS ['natur', 'leben', 'urlaub', 'sommer', 'lebendig', 'ferien', 'freiheit']\n",
      "c: AVG SIMILARITY 0.23858456703878583\n",
      "c: MEAN VALENCE 2.511764705882353\n",
      "c: MEAN VALENCE STD 0.6550264095786771\n",
      "c: MEAN AROUSAL 2.6699929971988796\n",
      "c: MEAN AROUSAL STD 1.1592823878205747\n",
      "c: SUGGESTION VALUE 2.948329686610483\n",
      "d: ITEMS ['genießen', 'positiv', 'zuhause', 'wahrheit', 'küssen', 'gesund', 'lieben', 'liebe']\n",
      "d: AVG SIMILARITY 0.16617824217038496\n",
      "d: MEAN VALENCE 2.580882352941176\n",
      "d: MEAN VALENCE STD 0.6299286371859685\n",
      "d: MEAN AROUSAL 2.7168991719494815\n",
      "d: MEAN AROUSAL STD 1.265269049634756\n",
      "d: SUGGESTION VALUE 3.1279681364569645\n",
      "1 ['genießen', 'positiv', 'zuhause', 'wahrheit', 'küssen', 'gesund', 'lieben', 'liebe']\n",
      "2 ['natur', 'leben', 'urlaub', 'sommer', 'lebendig', 'ferien', 'freiheit']\n",
      "3 ['spaß', 'musik', 'fantasie', 'sex', 'glück', 'freude']\n",
      "4 ['perfekt', 'super', 'freund', 'lachen']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = 2\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"DFFF_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] >= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "top_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"DFFF_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelDFFF.key_to_index[word] for word in high_valence_words]\n",
    "valence_word_vectors = [modelDFFF.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation on PCA\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = high_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "\n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_valence_words)[class_members])))\n",
    "    for member1 in np.array(high_valence_words)[class_members]:\n",
    "        for member2 in np.array(high_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelDFFF.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))                        \n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_val_DFFF = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_val_DFFF.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_val_DFFF, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff5478d",
   "metadata": {},
   "source": [
    "### 2. Low Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9da0fcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: ['alptraum', 'mord', 'strafe', 'gefängnis'], 0: ['tod', 'tot', 'leiche', 'negativ', 'unfall', 'grab', 'schlecht', 'streit', 'lüge'], 1: ['töten', 'zerstören', 'waffe'], 3: ['gewalt', 'angst', 'tote', 'gift', 'verlust'], 2: ['erzfeind', 'stehlen', 'fluch'], 5: ['einsam']}\n",
      "a: ITEMS ['tod', 'tot', 'leiche', 'negativ', 'unfall', 'grab', 'schlecht', 'streit', 'lüge']\n",
      "a: AVG SIMILARITY 0.19258663948211405\n",
      "a: MEAN VALENCE -2.3797385620915033\n",
      "a: MEAN VALENCE STD 0.734109942174734\n",
      "a: MEAN AROUSAL 3.9797178130511464\n",
      "a: MEAN AROUSAL STD 0.9027526471734532\n",
      "a: SUGGESTION VALUE 2.851675198947755\n",
      "b: ITEMS ['töten', 'zerstören', 'waffe']\n",
      "b: AVG SIMILARITY 0.18203230450550714\n",
      "b: MEAN VALENCE -2.52843137254902\n",
      "b: MEAN VALENCE STD 0.7754677122323823\n",
      "b: MEAN AROUSAL 4.2\n",
      "b: MEAN AROUSAL STD 1.0595421250470258\n",
      "b: SUGGESTION VALUE 2.2399997037772352\n",
      "c: ITEMS ['erzfeind', 'stehlen', 'fluch']\n",
      "c: AVG SIMILARITY 0.18986394504706064\n",
      "c: MEAN VALENCE -2.266666666666667\n",
      "c: MEAN VALENCE STD 0.5616370213557839\n",
      "c: MEAN AROUSAL 3.6425925925925924\n",
      "c: MEAN AROUSAL STD 1.1049889985591574\n",
      "c: SUGGESTION VALUE 2.1935761925381145\n",
      "d: ITEMS ['gewalt', 'angst', 'tote', 'gift', 'verlust']\n",
      "d: AVG SIMILARITY 0.22379375174641608\n",
      "d: MEAN VALENCE -2.5200000000000005\n",
      "d: MEAN VALENCE STD 0.6931139572986731\n",
      "d: MEAN AROUSAL 4.082913165266106\n",
      "d: MEAN AROUSAL STD 0.8080018832901044\n",
      "d: SUGGESTION VALUE 2.6172448122449454\n",
      "e: ITEMS ['alptraum', 'mord', 'strafe', 'gefängnis']\n",
      "e: AVG SIMILARITY 0.2510571206609408\n",
      "e: MEAN VALENCE -2.5661764705882355\n",
      "e: MEAN VALENCE STD 0.6663259286012783\n",
      "e: MEAN AROUSAL 3.9470981375006144\n",
      "e: MEAN AROUSAL STD 0.8695961097128702\n",
      "e: SUGGESTION VALUE 2.614441707121412\n",
      "f: ITEMS ['einsam']\n",
      "f: MEAN VALENCE -2.2\n",
      "f: MEAN VALENCE STD 0.92\n",
      "f: MEAN AROUSAL 3.1\n",
      "f: MEAN AROUSAL STD 1.3337718577107005\n",
      "f: SUGGESTION VALUE 0\n",
      "1 ['tod', 'tot', 'leiche', 'negativ', 'unfall', 'grab', 'schlecht', 'streit', 'lüge']\n",
      "2 ['gewalt', 'angst', 'tote', 'gift', 'verlust']\n",
      "3 ['alptraum', 'mord', 'strafe', 'gefängnis']\n",
      "4 ['töten', 'zerstören', 'waffe']\n",
      "5 ['erzfeind', 'stehlen', 'fluch']\n",
      "6 ['einsam']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = -2\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"DFFF_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] <= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"DFFF_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelDFFF.key_to_index[word] for word in low_valence_words]\n",
    "valence_word_vectors = [modelDFFF.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = low_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "    \n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_valence_words)[class_members])))\n",
    "    for member1 in np.array(low_valence_words)[class_members]:\n",
    "        for member2 in np.array(low_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelDFFF.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "    \n",
    "low_val_DFFF = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_val_DFFF.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_val_DFFF, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0751fd49",
   "metadata": {},
   "source": [
    "### 3. High Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daccfb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: ['wahnsinn', 'panisch', 'schrei', 'alptraum'], 4: ['zorn', 'macht', 'schreck', 'schmerz', 'leid', 'gefahr', 'angst', 'panik'], 2: ['leiche', 'tot', 'tote', 'waffe', 'mord', 'notfall'], 3: ['feind', 'sex', 'gewalt'], 0: ['geburt', 'unfall', 'trennung'], 1: ['drohung']}\n",
      "a: ITEMS ['geburt', 'unfall', 'trennung']\n",
      "a: AVG SIMILARITY 0.29985249042510986\n",
      "a: MEAN VALENCE -0.7166666666666668\n",
      "a: MEAN VALENCE STD 0.8438043993501712\n",
      "a: MEAN AROUSAL 4.236227824463119\n",
      "a: MEAN AROUSAL STD 0.7849755625877451\n",
      "a: SUGGESTION VALUE 4.342372638881848\n",
      "b: ITEMS ['drohung']\n",
      "b: MEAN VALENCE -2.1\n",
      "b: MEAN VALENCE STD 0.5676462121975466\n",
      "b: MEAN AROUSAL 4.176470588235294\n",
      "b: MEAN AROUSAL STD 0.9510056596602792\n",
      "b: SUGGESTION VALUE 0\n",
      "c: ITEMS ['leiche', 'tot', 'tote', 'waffe', 'mord', 'notfall']\n",
      "c: AVG SIMILARITY 0.21532328575849533\n",
      "c: MEAN VALENCE -2.4\n",
      "c: MEAN VALENCE STD 0.7249168763643997\n",
      "c: MEAN AROUSAL 4.282990974167444\n",
      "c: MEAN AROUSAL STD 0.8445978068412491\n",
      "c: SUGGESTION VALUE 4.8963294908586334\n",
      "d: ITEMS ['feind', 'sex', 'gewalt']\n",
      "d: AVG SIMILARITY 0.2018724133570989\n",
      "d: MEAN VALENCE -0.7490196078431374\n",
      "d: MEAN VALENCE STD 0.7119790668752422\n",
      "d: MEAN AROUSAL 4.288095238095239\n",
      "d: MEAN AROUSAL STD 0.7810415524007505\n",
      "d: SUGGESTION VALUE 4.293545575414594\n",
      "e: ITEMS ['zorn', 'macht', 'schreck', 'schmerz', 'leid', 'gefahr', 'angst', 'panik']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: AVG SIMILARITY 0.20316703444612877\n",
      "e: MEAN VALENCE -1.6544117647058825\n",
      "e: MEAN VALENCE STD 1.0615437050600067\n",
      "e: MEAN AROUSAL 4.263562398643668\n",
      "e: MEAN AROUSAL STD 0.7630297015261224\n",
      "e: SUGGESTION VALUE 5.472051330558842\n",
      "f: ITEMS ['wahnsinn', 'panisch', 'schrei', 'alptraum']\n",
      "f: AVG SIMILARITY 0.1668980544588218\n",
      "f: MEAN VALENCE -2.05\n",
      "f: MEAN VALENCE STD 0.842378981289877\n",
      "f: MEAN AROUSAL 4.320949432404541\n",
      "f: MEAN AROUSAL STD 0.7003996267194719\n",
      "f: SUGGESTION VALUE 4.603666545554026\n",
      "1 ['zorn', 'macht', 'schreck', 'schmerz', 'leid', 'gefahr', 'angst', 'panik']\n",
      "2 ['leiche', 'tot', 'tote', 'waffe', 'mord', 'notfall']\n",
      "3 ['wahnsinn', 'panisch', 'schrei', 'alptraum']\n",
      "4 ['geburt', 'unfall', 'trennung']\n",
      "5 ['feind', 'sex', 'gewalt']\n",
      "6 ['drohung']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"DFFF_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] >= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "top_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"DFFF_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelDFFF.key_to_index[word] for word in high_arousal_words]\n",
    "arousal_word_vectors = [modelDFFF.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = high_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_arousal_words)[class_members])))\n",
    "    for member1 in np.array(high_arousal_words)[class_members]:\n",
    "        for member2 in np.array(high_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelDFFF.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + sum(arousal_means) / len(arousal_means) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(high_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "\n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_arousal_DFFF = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_arousal_DFFF.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_arousal_DFFF, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52aa065",
   "metadata": {},
   "source": [
    "### 4. Low Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "975e5e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: ['schlaf', 'weich', 'decke', 'sofa', 'kissen', 'zimmer'], 2: ['still', 'pause', 'zaghaft', 'stumm'], 0: ['wiese', 'baum', 'klang', 'garten', 'himmel'], 6: ['liege', 'boden', 'gras', 'sand'], 1: ['wenig'], 4: ['ding', 'teller', 'erbse', 'eimer'], 3: ['gesund']}\n",
      "a: ITEMS ['wiese', 'baum', 'klang', 'garten', 'himmel']\n",
      "a: AVG SIMILARITY 0.2422032065689564\n",
      "a: MEAN VALENCE 1.6799999999999997\n",
      "a: MEAN VALENCE STD 0.9171854339985097\n",
      "a: MEAN AROUSAL 1.5503646370829034\n",
      "a: MEAN AROUSAL STD 0.7655993045508671\n",
      "a: SUGGESTION VALUE 2.4584236588003314\n",
      "b: ITEMS ['wenig']\n",
      "b: MEAN VALENCE -0.9\n",
      "b: MEAN VALENCE STD 0.99\n",
      "b: MEAN AROUSAL 1.5263157894736843\n",
      "b: MEAN AROUSAL STD 0.7723284457212328\n",
      "b: SUGGESTION VALUE 0\n",
      "c: ITEMS ['still', 'pause', 'zaghaft', 'stumm']\n",
      "c: AVG SIMILARITY 0.15788310642043749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: MEAN VALENCE 0.012499999999999983\n",
      "c: MEAN VALENCE STD 0.8191770199999999\n",
      "c: MEAN AROUSAL 1.4110275689223057\n",
      "c: MEAN AROUSAL STD 0.7162574934508305\n",
      "c: SUGGESTION VALUE 2.4682046137772704\n",
      "d: ITEMS ['gesund']\n",
      "d: MEAN VALENCE 2.7\n",
      "d: MEAN VALENCE STD 0.48\n",
      "d: MEAN AROUSAL 1.631578947368421\n",
      "d: MEAN AROUSAL STD 0.7608859102526819\n",
      "d: SUGGESTION VALUE 0\n",
      "e: ITEMS ['ding', 'teller', 'erbse', 'eimer']\n",
      "e: AVG SIMILARITY 0.19677923433482647\n",
      "e: MEAN VALENCE 0.31514705882352945\n",
      "e: MEAN VALENCE STD 0.8967921319694871\n",
      "e: MEAN AROUSAL 1.6029154995331467\n",
      "e: MEAN AROUSAL STD 0.7943356709064243\n",
      "e: SUGGESTION VALUE 2.1873376087150826\n",
      "f: ITEMS ['schlaf', 'weich', 'decke', 'sofa', 'kissen', 'zimmer']\n",
      "f: AVG SIMILARITY 0.2090221405029297\n",
      "f: MEAN VALENCE 1.4266666666666667\n",
      "f: MEAN VALENCE STD 0.9923830048485082\n",
      "f: MEAN AROUSAL 1.4980868019722509\n",
      "f: MEAN AROUSAL STD 0.6815172568312103\n",
      "f: SUGGESTION VALUE 2.7196143242910082\n",
      "g: ITEMS ['liege', 'boden', 'gras', 'sand']\n",
      "g: AVG SIMILARITY 0.33855227877696353\n",
      "g: MEAN VALENCE 0.9491176470588236\n",
      "g: MEAN VALENCE STD 1.0824353619512261\n",
      "g: MEAN AROUSAL 1.5846345029239768\n",
      "g: MEAN AROUSAL STD 0.7559636941236573\n",
      "g: SUGGESTION VALUE 2.428525673555012\n",
      "1 ['schlaf', 'weich', 'decke', 'sofa', 'kissen', 'zimmer']\n",
      "2 ['still', 'pause', 'zaghaft', 'stumm']\n",
      "3 ['wiese', 'baum', 'klang', 'garten', 'himmel']\n",
      "4 ['liege', 'boden', 'gras', 'sand']\n",
      "5 ['ding', 'teller', 'erbse', 'eimer']\n",
      "6 ['wenig']\n",
      "7 ['gesund']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"DFFF_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] <= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"DFFF_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelDFFF.key_to_index[word] for word in low_arousal_words]\n",
    "arousal_word_vectors = [modelDFFF.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = low_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_arousal_words)[class_members])))\n",
    "    for member1 in np.array(low_arousal_words)[class_members]:\n",
    "        for member2 in np.array(low_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelDFFF.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + (4 - sum(arousal_means) / len(arousal_means)) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(low_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "low_arousal_DFFF = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_arousal_DFFF.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_arousal_DFFF, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dba9d08",
   "metadata": {},
   "source": [
    "## 5. MITTELERDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cfe62a",
   "metadata": {},
   "source": [
    "### 1. High Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76555291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['natur', 'wahrheit', 'frieden', 'heilung', 'freiheit'], 1: ['leben', 'urlaub', 'lebendig', 'zuhause', 'freund'], 5: ['musik', 'glück', 'lachen', 'gesund', 'freude', 'lieben'], 0: ['sonnig', 'positiv', 'sommer'], 2: ['perfekt', 'super', 'liebe'], 4: ['fantasie', 'sex', 'küssen']}\n",
      "a: ITEMS ['sonnig', 'positiv', 'sommer']\n",
      "a: AVG SIMILARITY 0.23365899423758188\n",
      "a: MEAN VALENCE 2.433333333333333\n",
      "a: MEAN VALENCE STD 0.7427490666666667\n",
      "a: MEAN AROUSAL 2.4074074074074074\n",
      "a: MEAN AROUSAL STD 1.2161264916817012\n",
      "a: SUGGESTION VALUE 2.2275521049042806\n",
      "b: ITEMS ['leben', 'urlaub', 'lebendig', 'zuhause', 'freund']\n",
      "b: AVG SIMILARITY 0.21619584038853645\n",
      "b: MEAN VALENCE 2.478235294117647\n",
      "b: MEAN VALENCE STD 0.7066808329789417\n",
      "b: MEAN AROUSAL 2.4439413484692123\n",
      "b: MEAN AROUSAL STD 1.187826096136614\n",
      "b: SUGGESTION VALUE 2.536929060693035\n",
      "c: ITEMS ['perfekt', 'super', 'liebe']\n",
      "c: AVG SIMILARITY 0.19730295365055403\n",
      "c: MEAN VALENCE 2.6\n",
      "c: MEAN VALENCE STD 0.6192645033333333\n",
      "c: MEAN AROUSAL 3.3827485380116955\n",
      "c: MEAN AROUSAL STD 1.3935896186921497\n",
      "c: SUGGESTION VALUE 2.521351761048473\n",
      "d: ITEMS ['natur', 'wahrheit', 'frieden', 'heilung', 'freiheit']\n",
      "d: AVG SIMILARITY 0.20223161354660987\n",
      "d: MEAN VALENCE 2.5558823529411763\n",
      "d: MEAN VALENCE STD 0.6479014973181205\n",
      "d: MEAN AROUSAL 2.570588235294118\n",
      "d: MEAN AROUSAL STD 1.1273523825043381\n",
      "d: SUGGESTION VALUE 2.6932252673588444\n",
      "e: ITEMS ['fantasie', 'sex', 'küssen']\n",
      "e: AVG SIMILARITY 0.1547554979721705\n",
      "e: MEAN VALENCE 2.5392156862745097\n",
      "e: MEAN VALENCE STD 0.5455189314247254\n",
      "e: MEAN AROUSAL 3.4669312169312168\n",
      "e: MEAN AROUSAL STD 1.1918846941803427\n",
      "e: SUGGESTION VALUE 2.4871020391730156\n",
      "f: ITEMS ['musik', 'glück', 'lachen', 'gesund', 'freude', 'lieben']\n",
      "f: AVG SIMILARITY 0.17955443548659483\n",
      "f: MEAN VALENCE 2.62843137254902\n",
      "f: MEAN VALENCE STD 0.5358160183254337\n",
      "f: MEAN AROUSAL 2.721112831097351\n",
      "f: MEAN AROUSAL STD 1.2126604854996377\n",
      "f: SUGGESTION VALUE 3.0449248299504377\n",
      "1 ['musik', 'glück', 'lachen', 'gesund', 'freude', 'lieben']\n",
      "2 ['natur', 'wahrheit', 'frieden', 'heilung', 'freiheit']\n",
      "3 ['leben', 'urlaub', 'lebendig', 'zuhause', 'freund']\n",
      "4 ['perfekt', 'super', 'liebe']\n",
      "5 ['fantasie', 'sex', 'küssen']\n",
      "6 ['sonnig', 'positiv', 'sommer']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = 2\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"MITTELERDE_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] >= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "top_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"MITTELERDE_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelMittelerde.key_to_index[word] for word in high_valence_words]\n",
    "valence_word_vectors = [modelMittelerde.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation on PCA\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = high_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "\n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_valence_words)[class_members])))\n",
    "    for member1 in np.array(high_valence_words)[class_members]:\n",
    "        for member2 in np.array(high_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelMittelerde.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))                        \n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_val_Mittelerde = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_val_Mittelerde.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_val_Mittelerde, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9967fb",
   "metadata": {},
   "source": [
    "### 2. Low Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "431774b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['krieg', 'seuche', 'gift'], 5: ['mord', 'tod', 'angst', 'verrat', 'sucht'], 0: ['folter', 'qual', 'gewalt', 'negativ', 'strafe'], 1: ['alptraum', 'unfall'], 2: ['foltern', 'töten', 'zerstören', 'hassen', 'waffe'], 4: ['tote', 'tot', 'leiche', 'leichnam', 'leblos']}\n",
      "a: ITEMS ['folter', 'qual', 'gewalt', 'negativ', 'strafe']\n",
      "a: AVG SIMILARITY 0.20706625580787658\n",
      "a: MEAN VALENCE -2.6\n",
      "a: MEAN VALENCE STD 0.6860240335421105\n",
      "a: MEAN AROUSAL 4.09874686716792\n",
      "a: MEAN AROUSAL STD 0.7193675800404499\n",
      "a: SUGGESTION VALUE 2.7070470815618246\n",
      "b: ITEMS ['alptraum', 'unfall']\n",
      "b: AVG SIMILARITY 0.3417823314666748\n",
      "b: MEAN VALENCE -2.575\n",
      "b: MEAN VALENCE STD 0.6516379610168379\n",
      "b: MEAN AROUSAL 4.383753501400561\n",
      "b: MEAN AROUSAL STD 0.6623021631519119\n",
      "b: SUGGESTION VALUE 2.4973216684209456\n",
      "c: ITEMS ['foltern', 'töten', 'zerstören', 'hassen', 'waffe']\n",
      "c: AVG SIMILARITY 0.21811757311224939\n",
      "c: MEAN VALENCE -2.577058823529412\n",
      "c: MEAN VALENCE STD 0.6912806273394294\n",
      "c: MEAN AROUSAL 4.297777777777778\n",
      "c: MEAN AROUSAL STD 0.9636070030327499\n",
      "c: SUGGESTION VALUE 2.685163379782193\n",
      "d: ITEMS ['krieg', 'seuche', 'gift']\n",
      "d: AVG SIMILARITY 0.31322184205055237\n",
      "d: MEAN VALENCE -2.6333333333333333\n",
      "d: MEAN VALENCE STD 0.6650532876703118\n",
      "d: MEAN AROUSAL 4.273809523809524\n",
      "d: MEAN AROUSAL STD 0.8080352144634014\n",
      "d: SUGGESTION VALUE 2.641123622764426\n",
      "e: ITEMS ['tote', 'tot', 'leiche', 'leichnam', 'leblos']\n",
      "e: AVG SIMILARITY 0.36963521540164945\n",
      "e: MEAN VALENCE -2.45\n",
      "e: MEAN VALENCE STD 0.7943269182983338\n",
      "e: MEAN AROUSAL 3.985434173669468\n",
      "e: MEAN AROUSAL STD 0.9060153003083908\n",
      "e: SUGGESTION VALUE 2.5848636379712353\n",
      "f: ITEMS ['mord', 'tod', 'angst', 'verrat', 'sucht']\n",
      "f: AVG SIMILARITY 0.22541196197271346\n",
      "f: MEAN VALENCE -2.5799999999999996\n",
      "f: MEAN VALENCE STD 0.5833802787418417\n",
      "f: MEAN AROUSAL 4.176190476190476\n",
      "f: MEAN AROUSAL STD 0.951337624897171\n",
      "f: SUGGESTION VALUE 2.835938068598402\n",
      "1 ['mord', 'tod', 'angst', 'verrat', 'sucht']\n",
      "2 ['folter', 'qual', 'gewalt', 'negativ', 'strafe']\n",
      "3 ['foltern', 'töten', 'zerstören', 'hassen', 'waffe']\n",
      "4 ['krieg', 'seuche', 'gift']\n",
      "5 ['tote', 'tot', 'leiche', 'leichnam', 'leblos']\n",
      "6 ['alptraum', 'unfall']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = -2\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"MITTELERDE_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] <= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"MITTELERDE_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelMittelerde.key_to_index[word] for word in low_valence_words]\n",
    "valence_word_vectors = [modelMittelerde.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = low_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "    \n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_valence_words)[class_members])))\n",
    "    for member1 in np.array(low_valence_words)[class_members]:\n",
    "        for member2 in np.array(low_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelMittelerde.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "    \n",
    "low_val_Mittelerde = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_val_Mittelerde.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_val_Mittelerde, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49552149",
   "metadata": {},
   "source": [
    "### 3. High Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9872deac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: ['unfall', 'schrei', 'alptraum'], 0: ['waffe', 'sklave', 'hassen'], 2: ['seuche', 'blutig', 'mord', 'brutal', 'bestie'], 6: ['trennung', 'sex', 'gewalt', 'foltern', 'folter'], 3: ['ohrfeige', 'alarm', 'notfall'], 4: ['gefahr', 'unheil', 'krieg'], 1: ['angst', 'furcht', 'panik']}\n",
      "a: ITEMS ['waffe', 'sklave', 'hassen']\n",
      "a: AVG SIMILARITY 0.20239900797605515\n",
      "a: MEAN VALENCE -2.35\n",
      "a: MEAN VALENCE STD 0.7953565899999999\n",
      "a: MEAN AROUSAL 4.332776385407965\n",
      "a: MEAN AROUSAL STD 0.7671721704198582\n",
      "a: SUGGESTION VALUE 4.361934730983888\n",
      "b: ITEMS ['angst', 'furcht', 'panik']\n",
      "b: AVG SIMILARITY 0.5029648840427399\n",
      "b: MEAN VALENCE -2.2\n",
      "b: MEAN VALENCE STD 0.9231543621755721\n",
      "b: MEAN AROUSAL 4.4603174603174605\n",
      "b: MEAN AROUSAL STD 0.6296839533341932\n",
      "b: SUGGESTION VALUE 5.0166818374114825\n",
      "c: ITEMS ['seuche', 'blutig', 'mord', 'brutal', 'bestie']\n",
      "c: AVG SIMILARITY 0.2508745491504669\n",
      "c: MEAN VALENCE -2.2399999999999998\n",
      "c: MEAN VALENCE STD 0.7182654249071911\n",
      "c: MEAN AROUSAL 4.420034399724803\n",
      "c: MEAN AROUSAL STD 0.8409980043973577\n",
      "c: SUGGESTION VALUE 4.888044724454121\n",
      "d: ITEMS ['ohrfeige', 'alarm', 'notfall']\n",
      "d: AVG SIMILARITY 0.2357340008020401\n",
      "d: MEAN VALENCE -1.7\n",
      "d: MEAN VALENCE STD 0.7378643349057268\n",
      "d: MEAN AROUSAL 4.428785403050109\n",
      "d: MEAN AROUSAL STD 0.6450695154580844\n",
      "d: SUGGESTION VALUE 4.6530156770521796\n",
      "e: ITEMS ['gefahr', 'unheil', 'krieg']\n",
      "e: AVG SIMILARITY 0.33743947744369507\n",
      "e: MEAN VALENCE -2.283333333333333\n",
      "e: MEAN VALENCE STD 0.5342117220056126\n",
      "e: MEAN AROUSAL 4.493930905695612\n",
      "e: MEAN AROUSAL STD 0.6303073199927091\n",
      "e: SUGGESTION VALUE 4.8632556284750805\n",
      "f: ITEMS ['unfall', 'schrei', 'alptraum']\n",
      "f: AVG SIMILARITY 0.24277412394682565\n",
      "f: MEAN VALENCE -2.25\n",
      "f: MEAN VALENCE STD 0.8256879042703144\n",
      "f: MEAN AROUSAL 4.396186544793356\n",
      "f: MEAN AROUSAL STD 0.6723623117619827\n",
      "f: SUGGESTION VALUE 4.591833422996889\n",
      "g: ITEMS ['trennung', 'sex', 'gewalt', 'foltern', 'folter']\n",
      "g: AVG SIMILARITY 0.23813911750912667\n",
      "g: MEAN VALENCE -1.48\n",
      "g: MEAN VALENCE STD 0.5958940015089672\n",
      "g: MEAN AROUSAL 4.427411666420954\n",
      "g: MEAN AROUSAL STD 0.7129518690852548\n",
      "g: SUGGESTION VALUE 5.04462911897396\n",
      "1 ['trennung', 'sex', 'gewalt', 'foltern', 'folter']\n",
      "2 ['angst', 'furcht', 'panik']\n",
      "3 ['seuche', 'blutig', 'mord', 'brutal', 'bestie']\n",
      "4 ['gefahr', 'unheil', 'krieg']\n",
      "5 ['ohrfeige', 'alarm', 'notfall']\n",
      "6 ['unfall', 'schrei', 'alptraum']\n",
      "7 ['waffe', 'sklave', 'hassen']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"MITTELERDE_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] >= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "top_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"MITTELERDE_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelMittelerde.key_to_index[word] for word in high_arousal_words]\n",
    "arousal_word_vectors = [modelMittelerde.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = high_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_arousal_words)[class_members])))\n",
    "    for member1 in np.array(high_arousal_words)[class_members]:\n",
    "        for member2 in np.array(high_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelMittelerde.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + sum(arousal_means) / len(arousal_means) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(high_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "\n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_arousal_Mittelerde = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_arousal_Mittelerde.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_arousal_Mittelerde, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b52ec4",
   "metadata": {},
   "source": [
    "### 4. Low Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2b2c7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['schlaf', 'friede', 'segen', 'ding'], 4: ['still', 'pause', 'zaghaft', 'stumm'], 2: ['wiege', 'beutel', 'seife', 'schale', 'kamin', 'harfe', 'wenig', 'traube'], 3: ['buche', 'wiese', 'murmel', 'baum', 'boden', 'weide'], 0: ['weich', 'seide', 'liege']}\n",
      "a: ITEMS ['weich', 'seide', 'liege']\n",
      "a: AVG SIMILARITY 0.2560364753007889\n",
      "a: MEAN VALENCE 1.383333333333333\n",
      "a: MEAN VALENCE STD 0.8504703326835047\n",
      "a: MEAN AROUSAL 1.4551083591331269\n",
      "a: MEAN AROUSAL STD 0.7186285995138822\n",
      "a: SUGGESTION VALUE 2.410521977966332\n",
      "b: ITEMS ['schlaf', 'friede', 'segen', 'ding']\n",
      "b: AVG SIMILARITY 0.15586992353200912\n",
      "b: MEAN VALENCE 1.4676470588235295\n",
      "b: MEAN VALENCE STD 0.9968674659724254\n",
      "b: MEAN AROUSAL 1.4027046783625732\n",
      "b: MEAN AROUSAL STD 0.7118649636057858\n",
      "b: SUGGESTION VALUE 2.4812132503673774\n",
      "c: ITEMS ['wiege', 'beutel', 'seife', 'schale', 'kamin', 'harfe', 'wenig', 'traube']\n",
      "c: AVG SIMILARITY 0.19899939931929111\n",
      "c: MEAN VALENCE 0.83125\n",
      "c: MEAN VALENCE STD 0.90787606875\n",
      "c: MEAN AROUSAL 1.4660087719298247\n",
      "c: MEAN AROUSAL STD 0.6541672456418604\n",
      "c: SUGGESTION VALUE 3.0713689220389906\n",
      "d: ITEMS ['buche', 'wiese', 'murmel', 'baum', 'boden', 'weide']\n",
      "d: AVG SIMILARITY 0.2705503314733505\n",
      "d: MEAN VALENCE 1.125\n",
      "d: MEAN VALENCE STD 0.9727185012739975\n",
      "d: MEAN AROUSAL 1.4774968466918932\n",
      "d: MEAN AROUSAL STD 0.6268964847773428\n",
      "d: SUGGESTION VALUE 2.9028575526148437\n",
      "e: ITEMS ['still', 'pause', 'zaghaft', 'stumm']\n",
      "e: AVG SIMILARITY 0.15588922627891103\n",
      "e: MEAN VALENCE 0.012499999999999983\n",
      "e: MEAN VALENCE STD 0.8191770199999999\n",
      "e: MEAN AROUSAL 1.4110275689223057\n",
      "e: MEAN AROUSAL STD 0.7162574934508305\n",
      "e: SUGGESTION VALUE 2.465781040003494\n",
      "1 ['wiege', 'beutel', 'seife', 'schale', 'kamin', 'harfe', 'wenig', 'traube']\n",
      "2 ['buche', 'wiese', 'murmel', 'baum', 'boden', 'weide']\n",
      "3 ['schlaf', 'friede', 'segen', 'ding']\n",
      "4 ['still', 'pause', 'zaghaft', 'stumm']\n",
      "5 ['weich', 'seide', 'liege']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"MITTELERDE_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] <= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"MITTELERDE_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelMittelerde.key_to_index[word] for word in low_arousal_words]\n",
    "arousal_word_vectors = [modelMittelerde.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = low_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_arousal_words)[class_members])))\n",
    "    for member1 in np.array(low_arousal_words)[class_members]:\n",
    "        for member2 in np.array(low_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelMittelerde.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + (4 - sum(arousal_means) / len(arousal_means)) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(low_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "low_arousal_Mittelerde = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_arousal_Mittelerde.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_arousal_Mittelerde, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f244f",
   "metadata": {},
   "source": [
    "## 6. JACKSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9935a6",
   "metadata": {},
   "source": [
    "### 1. High Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67f72936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['fee', 'natur', 'wahrheit', 'lebendig', 'lieben', 'freiheit'], 2: ['schatz', 'perfekt', 'super'], 4: ['spaß', 'glück', 'gesund'], 5: ['genießen', 'freund', 'küssen', 'lachen'], 3: ['leben', 'musik', 'urlaub', 'sommer', 'zuhause', 'ferien', 'liebe'], 1: ['positiv', 'freude']}\n",
      "a: ITEMS ['fee', 'natur', 'wahrheit', 'lebendig', 'lieben', 'freiheit']\n",
      "a: AVG SIMILARITY 0.1592286874850591\n",
      "a: MEAN VALENCE 2.5259803921568627\n",
      "a: MEAN VALENCE STD 0.6775864694434531\n",
      "a: MEAN AROUSAL 3.0092592592592595\n",
      "a: MEAN AROUSAL STD 1.1350708043280056\n",
      "a: SUGGESTION VALUE 2.6904063079471525\n",
      "b: ITEMS ['positiv', 'freude']\n",
      "b: AVG SIMILARITY 0.25711965560913086\n",
      "b: MEAN VALENCE 2.55\n",
      "b: MEAN VALENCE STD 0.705620285\n",
      "b: MEAN AROUSAL 3.011437908496732\n",
      "b: MEAN AROUSAL STD 1.2603425937469277\n",
      "b: SUGGESTION VALUE 2.3169030560965664\n",
      "c: ITEMS ['schatz', 'perfekt', 'super']\n",
      "c: AVG SIMILARITY 0.23613144954045615\n",
      "c: MEAN VALENCE 2.4\n",
      "c: MEAN VALENCE STD 0.8328944326835045\n",
      "c: MEAN AROUSAL 3.3388888888888886\n",
      "c: MEAN AROUSAL STD 1.3107001680197032\n",
      "c: SUGGESTION VALUE 2.0874722516390287\n",
      "d: ITEMS ['leben', 'musik', 'urlaub', 'sommer', 'zuhause', 'ferien', 'liebe']\n",
      "d: AVG SIMILARITY 0.23811779508278483\n",
      "d: MEAN VALENCE 2.5331932773109243\n",
      "d: MEAN VALENCE STD 0.5837018581259289\n",
      "d: MEAN AROUSAL 2.444205489213229\n",
      "d: MEAN AROUSAL STD 1.2932957896707047\n",
      "d: SUGGESTION VALUE 3.0781858500029013\n",
      "e: ITEMS ['spaß', 'glück', 'gesund']\n",
      "e: AVG SIMILARITY 0.21208708981672922\n",
      "e: MEAN VALENCE 2.547058823529412\n",
      "e: MEAN VALENCE STD 0.6053551615847312\n",
      "e: MEAN AROUSAL 2.7146198830409354\n",
      "e: MEAN AROUSAL STD 1.251885990379556\n",
      "e: SUGGESTION VALUE 2.493282019007802\n",
      "f: ITEMS ['genießen', 'freund', 'küssen', 'lachen']\n",
      "f: AVG SIMILARITY 0.21595523009697595\n",
      "f: MEAN VALENCE 2.5367647058823533\n",
      "f: MEAN VALENCE STD 0.6070952440717533\n",
      "f: MEAN AROUSAL 2.5494674185463655\n",
      "f: MEAN AROUSAL STD 1.292573535751557\n",
      "f: SUGGESTION VALUE 2.6080202231679834\n",
      "1 ['leben', 'musik', 'urlaub', 'sommer', 'zuhause', 'ferien', 'liebe']\n",
      "2 ['fee', 'natur', 'wahrheit', 'lebendig', 'lieben', 'freiheit']\n",
      "3 ['genießen', 'freund', 'küssen', 'lachen']\n",
      "4 ['spaß', 'glück', 'gesund']\n",
      "5 ['positiv', 'freude']\n",
      "6 ['schatz', 'perfekt', 'super']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = 2\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"JACKSON_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] >= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "top_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"JACKSON_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelJackson.key_to_index[word] for word in high_valence_words]\n",
    "valence_word_vectors = [modelJackson.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation on PCA\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = high_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "\n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_valence_words)[class_members])))\n",
    "    for member1 in np.array(high_valence_words)[class_members]:\n",
    "        for member2 in np.array(high_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelJackson.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))                        \n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_val_Jackson = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_val_Jackson.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_val_Jackson, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d53c86f",
   "metadata": {},
   "source": [
    "### 2. Low Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1a77fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['krieg', 'tote', 'strafe', 'streit'], 1: ['alptraum', 'tod', 'grausam', 'verlust', 'abschied'], 2: ['töten', 'angst', 'zerstören', 'tot', 'hassen', 'leiche', 'stehlen'], 3: ['qual', 'gift', 'waffe', 'lüge', 'armee'], 4: ['grab', 'schlecht', 'gefängnis', 'einsam']}\n",
      "a: ITEMS ['krieg', 'tote', 'strafe', 'streit']\n",
      "a: AVG SIMILARITY 0.22975971053044\n",
      "a: MEAN VALENCE -2.5250000000000004\n",
      "a: MEAN VALENCE STD 0.6171679692076537\n",
      "a: MEAN AROUSAL 4.139355742296919\n",
      "a: MEAN AROUSAL STD 0.689857151713467\n",
      "a: SUGGESTION VALUE 2.598256121526231\n",
      "b: ITEMS ['alptraum', 'tod', 'grausam', 'verlust', 'abschied']\n",
      "b: AVG SIMILARITY 0.20284271240234375\n",
      "b: MEAN VALENCE -2.42\n",
      "b: MEAN VALENCE STD 0.7163172978373178\n",
      "b: MEAN AROUSAL 3.8376283846872083\n",
      "b: MEAN AROUSAL STD 1.0062252098323659\n",
      "b: SUGGESTION VALUE 2.4332632350470123\n",
      "c: ITEMS ['töten', 'angst', 'zerstören', 'tot', 'hassen', 'leiche', 'stehlen']\n",
      "c: AVG SIMILARITY 0.1900075881608895\n",
      "c: MEAN VALENCE -2.4978991596638656\n",
      "c: MEAN VALENCE STD 0.7277061850681782\n",
      "c: MEAN AROUSAL 4.15827664399093\n",
      "c: MEAN AROUSAL STD 0.915795175067459\n",
      "c: SUGGESTION VALUE 2.7581990403457994\n",
      "d: ITEMS ['qual', 'gift', 'waffe', 'lüge', 'armee']\n",
      "d: AVG SIMILARITY 0.19906756319105626\n",
      "d: MEAN VALENCE -2.353529411764706\n",
      "d: MEAN VALENCE STD 0.749922508410758\n",
      "d: MEAN AROUSAL 4.080952380952381\n",
      "d: MEAN AROUSAL STD 0.8973089339384813\n",
      "d: SUGGESTION VALUE 2.3007201848409125\n",
      "e: ITEMS ['grab', 'schlecht', 'gefängnis', 'einsam']\n",
      "e: AVG SIMILARITY 0.1936785653233528\n",
      "e: MEAN VALENCE -2.2661764705882352\n",
      "e: MEAN VALENCE STD 0.8009252708410545\n",
      "e: MEAN AROUSAL 3.427046783625731\n",
      "e: MEAN AROUSAL STD 1.2284885408584456\n",
      "e: SUGGESTION VALUE 2.016439497754266\n",
      "1 ['töten', 'angst', 'zerstören', 'tot', 'hassen', 'leiche', 'stehlen']\n",
      "2 ['krieg', 'tote', 'strafe', 'streit']\n",
      "3 ['alptraum', 'tod', 'grausam', 'verlust', 'abschied']\n",
      "4 ['qual', 'gift', 'waffe', 'lüge', 'armee']\n",
      "5 ['grab', 'schlecht', 'gefängnis', 'einsam']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = -2\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"JACKSON_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] <= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"JACKSON_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelJackson.key_to_index[word] for word in low_valence_words]\n",
    "valence_word_vectors = [modelJackson.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = low_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "    \n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_valence_words)[class_members])))\n",
    "    for member1 in np.array(low_valence_words)[class_members]:\n",
    "        for member2 in np.array(low_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelJackson.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "    \n",
    "low_val_Jackson = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_val_Jackson.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_val_Jackson, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdddc133",
   "metadata": {},
   "source": [
    "### 3. High Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbf77252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['dolch', 'scharf', 'waffe'], 4: ['lüge', 'wahnsinn', 'zorn', 'leiche', 'schreck', 'schmerz', 'panisch', 'gefahr', 'angst', 'panik'], 2: ['elend', 'schrei', 'alptraum'], 3: ['sturm', 'macht', 'geburt', 'tote', 'krieg'], 1: ['feind', 'leid', 'tot', 'hassen']}\n",
      "a: ITEMS ['dolch', 'scharf', 'waffe']\n",
      "a: AVG SIMILARITY 0.22201532125473022\n",
      "a: MEAN VALENCE -1.2166666666666668\n",
      "a: MEAN VALENCE STD 1.0200567651571266\n",
      "a: MEAN AROUSAL 4.131996658312448\n",
      "a: MEAN AROUSAL STD 0.8493489667196584\n",
      "a: SUGGESTION VALUE 4.05708552024761\n",
      "b: ITEMS ['feind', 'leid', 'tot', 'hassen']\n",
      "b: AVG SIMILARITY 0.17434664749695608\n",
      "b: MEAN VALENCE -2.2867647058823533\n",
      "b: MEAN VALENCE STD 0.940749847377664\n",
      "b: MEAN AROUSAL 4.231944444444445\n",
      "b: MEAN AROUSAL STD 0.8703409258684832\n",
      "b: SUGGESTION VALUE 4.297969526550171\n",
      "c: ITEMS ['elend', 'schrei', 'alptraum']\n",
      "c: AVG SIMILARITY 0.22127488007148108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: MEAN VALENCE -2.1666666666666665\n",
      "c: MEAN VALENCE STD 0.8487477742703143\n",
      "c: MEAN AROUSAL 4.3501547987616105\n",
      "c: MEAN AROUSAL STD 0.7615509744586365\n",
      "c: SUGGESTION VALUE 4.410410835151478\n",
      "d: ITEMS ['sturm', 'macht', 'geburt', 'tote', 'krieg']\n",
      "d: AVG SIMILARITY 0.24368526935577392\n",
      "d: MEAN VALENCE -0.72\n",
      "d: MEAN VALENCE STD 0.858418484042998\n",
      "d: MEAN AROUSAL 4.234873949579831\n",
      "d: MEAN AROUSAL STD 0.8300607586082899\n",
      "d: SUGGESTION VALUE 4.656511315725392\n",
      "e: ITEMS ['lüge', 'wahnsinn', 'zorn', 'leiche', 'schreck', 'schmerz', 'panisch', 'gefahr', 'angst', 'panik']\n",
      "e: AVG SIMILARITY 0.22440432392888598\n",
      "e: MEAN VALENCE -1.9702941176470588\n",
      "e: MEAN VALENCE STD 0.901858680819976\n",
      "e: MEAN AROUSAL 4.232357855422871\n",
      "e: MEAN AROUSAL STD 0.7507011664832689\n",
      "e: SUGGESTION VALUE 6.036782870370844\n",
      "1 ['lüge', 'wahnsinn', 'zorn', 'leiche', 'schreck', 'schmerz', 'panisch', 'gefahr', 'angst', 'panik']\n",
      "2 ['sturm', 'macht', 'geburt', 'tote', 'krieg']\n",
      "3 ['elend', 'schrei', 'alptraum']\n",
      "4 ['feind', 'leid', 'tot', 'hassen']\n",
      "5 ['dolch', 'scharf', 'waffe']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"JACKSON_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] >= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "top_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"JACKSON_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelJackson.key_to_index[word] for word in high_arousal_words]\n",
    "arousal_word_vectors = [modelJackson.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = high_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_arousal_words)[class_members])))\n",
    "    for member1 in np.array(high_arousal_words)[class_members]:\n",
    "        for member2 in np.array(high_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelJackson.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + sum(arousal_means) / len(arousal_means) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(high_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "\n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_arousal_Jackson = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_arousal_Jackson.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_arousal_Jackson, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb759e",
   "metadata": {},
   "source": [
    "### 4. Low Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "127ecb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: ['schlaf', 'gesund'], 1: ['still', 'stumm'], 3: ['weich', 'wiese', 'baum', 'boden', 'gras', 'garten', 'kissen', 'himmel', 'sand'], 0: ['pause', 'friede', 'wenig'], 4: ['kamin', 'teller', 'decke', 'sofa', 'schlicht', 'zimmer'], 2: ['segen', 'ding', 'klang']}\n",
      "a: ITEMS ['pause', 'friede', 'wenig']\n",
      "a: AVG SIMILARITY 0.15853899468978247\n",
      "a: MEAN VALENCE 0.8833333333333333\n",
      "a: MEAN VALENCE STD 1.05766827\n",
      "a: MEAN AROUSAL 1.4357560568086882\n",
      "a: MEAN AROUSAL STD 0.7367554964042022\n",
      "a: SUGGESTION VALUE 2.2990750169396876\n",
      "b: ITEMS ['still', 'stumm']\n",
      "b: AVG SIMILARITY 0.2627981901168823\n",
      "b: MEAN VALENCE -0.15000000000000002\n",
      "b: MEAN VALENCE STD 0.86\n",
      "b: MEAN AROUSAL 1.3947368421052633\n",
      "b: MEAN AROUSAL STD 0.7631127990415713\n",
      "b: SUGGESTION VALUE 2.3207057752394777\n",
      "c: ITEMS ['segen', 'ding', 'klang']\n",
      "c: AVG SIMILARITY 0.15625752011934915\n",
      "c: MEAN VALENCE 0.9568627450980394\n",
      "c: MEAN VALENCE STD 0.923338936742171\n",
      "c: MEAN AROUSAL 1.5615009746588695\n",
      "c: MEAN AROUSAL STD 0.8311413107293601\n",
      "c: SUGGESTION VALUE 2.041605086105612\n",
      "d: ITEMS ['weich', 'wiese', 'baum', 'boden', 'gras', 'garten', 'kissen', 'himmel', 'sand']\n",
      "d: AVG SIMILARITY 0.26357799106174046\n",
      "d: MEAN VALENCE 1.3829411764705881\n",
      "d: MEAN VALENCE STD 0.9787562997109307\n",
      "d: MEAN AROUSAL 1.5556197683751862\n",
      "d: MEAN AROUSAL STD 0.7297893536663074\n",
      "d: SUGGESTION VALUE 3.0687891824814186\n",
      "e: ITEMS ['kamin', 'teller', 'decke', 'sofa', 'schlicht', 'zimmer']\n",
      "e: AVG SIMILARITY 0.26897219121456145\n",
      "e: MEAN VALENCE 1.0083333333333333\n",
      "e: MEAN VALENCE STD 0.9899781838465493\n",
      "e: MEAN AROUSAL 1.604074074074074\n",
      "e: MEAN AROUSAL STD 0.7472028667730511\n",
      "e: SUGGESTION VALUE 2.56989504506467\n",
      "f: ITEMS ['schlaf', 'gesund']\n",
      "f: AVG SIMILARITY 0.2259504646062851\n",
      "f: MEAN VALENCE 2.3\n",
      "f: MEAN VALENCE STD 0.7372144630058766\n",
      "f: MEAN AROUSAL 1.3684210526315792\n",
      "f: MEAN AROUSAL STD 0.5380938389474939\n",
      "f: SUGGESTION VALUE 2.557177719262501\n",
      "1 ['weich', 'wiese', 'baum', 'boden', 'gras', 'garten', 'kissen', 'himmel', 'sand']\n",
      "2 ['kamin', 'teller', 'decke', 'sofa', 'schlicht', 'zimmer']\n",
      "3 ['schlaf', 'gesund']\n",
      "4 ['still', 'stumm']\n",
      "5 ['pause', 'friede', 'wenig']\n",
      "6 ['segen', 'ding', 'klang']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"JACKSON_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] <= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"JACKSON_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelJackson.key_to_index[word] for word in low_arousal_words]\n",
    "arousal_word_vectors = [modelJackson.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = low_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_arousal_words)[class_members])))\n",
    "    for member1 in np.array(low_arousal_words)[class_members]:\n",
    "        for member2 in np.array(low_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelJackson.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + (4 - sum(arousal_means) / len(arousal_means)) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(low_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "low_arousal_Jackson = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_arousal_Jackson.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_arousal_Jackson, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0c8933",
   "metadata": {},
   "source": [
    "## 7. PANEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de6ca2",
   "metadata": {},
   "source": [
    "### 1. High Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73b1632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: ['gefühl', 'genießen', 'natur', 'sommer', 'zuhause', 'lieben', 'freiheit'], 0: ['himmel'], 1: ['lächeln', 'wahrheit', 'lachen'], 3: ['geschenk', 'schatz', 'spaß', 'positiv', 'perfekt', 'super', 'glück'], 2: ['leben', 'freund', 'freude'], 4: ['musik', 'lebendig', 'küssen', 'gesund']}\n",
      "a: ITEMS ['himmel']\n",
      "a: MEAN VALENCE 2.25\n",
      "a: MEAN VALENCE STD 0.91046547\n",
      "a: MEAN AROUSAL 1.65\n",
      "a: MEAN AROUSAL STD 0.9880869341680842\n",
      "a: SUGGESTION VALUE 0\n",
      "b: ITEMS ['lächeln', 'wahrheit', 'lachen']\n",
      "b: AVG SIMILARITY 0.21159330507119498\n",
      "b: MEAN VALENCE 2.4803921568627456\n",
      "b: MEAN VALENCE STD 0.7354398333414088\n",
      "b: MEAN AROUSAL 2.73015873015873\n",
      "b: MEAN AROUSAL STD 1.216288911502619\n",
      "b: SUGGESTION VALUE 2.2649461332994303\n",
      "c: ITEMS ['leben', 'freund', 'freude']\n",
      "c: AVG SIMILARITY 0.21969045201937357\n",
      "c: MEAN VALENCE 2.547058823529412\n",
      "c: MEAN VALENCE STD 0.6790400545693869\n",
      "c: MEAN AROUSAL 2.710354317165463\n",
      "c: MEAN AROUSAL STD 1.3166120451268373\n",
      "c: SUGGESTION VALUE 2.4167843869362766\n",
      "d: ITEMS ['geschenk', 'schatz', 'spaß', 'positiv', 'perfekt', 'super', 'glück']\n",
      "d: AVG SIMILARITY 0.18619867786765099\n",
      "d: MEAN VALENCE 2.405882352941177\n",
      "d: MEAN VALENCE STD 0.7642424772164657\n",
      "d: MEAN AROUSAL 3.230092387832326\n",
      "d: MEAN AROUSAL STD 1.3209281840864995\n",
      "d: SUGGESTION VALUE 2.571952401307202\n",
      "e: ITEMS ['musik', 'lebendig', 'küssen', 'gesund']\n",
      "e: AVG SIMILARITY 0.20955548714846373\n",
      "e: MEAN VALENCE 2.5544117647058826\n",
      "e: MEAN VALENCE STD 0.6090964813213829\n",
      "e: MEAN AROUSAL 2.4289264828738513\n",
      "e: MEAN AROUSAL STD 1.177014034990097\n",
      "e: SUGGESTION VALUE 2.6192588895251334\n",
      "f: ITEMS ['gefühl', 'genießen', 'natur', 'sommer', 'zuhause', 'lieben', 'freiheit']\n",
      "f: AVG SIMILARITY 0.19127442971581504\n",
      "f: MEAN VALENCE 2.4836134453781513\n",
      "f: MEAN VALENCE STD 0.6654300079136205\n",
      "f: MEAN AROUSAL 2.7006535947712416\n",
      "f: MEAN AROUSAL STD 1.1839239996841748\n",
      "f: SUGGESTION VALUE 2.827509014219392\n",
      "1 ['gefühl', 'genießen', 'natur', 'sommer', 'zuhause', 'lieben', 'freiheit']\n",
      "2 ['musik', 'lebendig', 'küssen', 'gesund']\n",
      "3 ['geschenk', 'schatz', 'spaß', 'positiv', 'perfekt', 'super', 'glück']\n",
      "4 ['leben', 'freund', 'freude']\n",
      "5 ['lächeln', 'wahrheit', 'lachen']\n",
      "6 ['himmel']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = 2\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"PANEM_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] >= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "top_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"PANEM_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelPanem.key_to_index[word] for word in high_valence_words]\n",
    "valence_word_vectors = [modelPanem.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation on PCA\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = high_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "\n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_valence_words)[class_members])))\n",
    "    for member1 in np.array(high_valence_words)[class_members]:\n",
    "        for member2 in np.array(high_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelPanem.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))                        \n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_val_Panem = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_val_Panem.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_val_Panem, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8ba27",
   "metadata": {},
   "source": [
    "### 2. Low Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61171378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['krieg', 'zerstören', 'strafe', 'streit', 'tragisch'], 3: ['alptraum', 'angst', 'furcht', 'einsam'], 4: ['tod', 'verlust', 'grausam', 'lüge', 'traurig', 'abschied'], 1: ['töten', 'gift', 'waffe', 'stehlen'], 2: ['tote', 'tot', 'leiche', 'schlecht', 'sarg', 'panisch']}\n",
      "a: ITEMS ['krieg', 'zerstören', 'strafe', 'streit', 'tragisch']\n",
      "a: AVG SIMILARITY 0.27205989211797715\n",
      "a: MEAN VALENCE -2.425882352941177\n",
      "a: MEAN VALENCE STD 0.6810176258180624\n",
      "a: MEAN AROUSAL 4.0285714285714285\n",
      "a: MEAN AROUSAL STD 0.8090459904161067\n",
      "a: SUGGESTION VALUE 2.574163704489739\n",
      "b: ITEMS ['töten', 'gift', 'waffe', 'stehlen']\n",
      "b: AVG SIMILARITY 0.18814480118453503\n",
      "b: MEAN VALENCE -2.4389705882352946\n",
      "b: MEAN VALENCE STD 0.639471941710974\n",
      "b: MEAN AROUSAL 4.07063492063492\n",
      "b: MEAN AROUSAL STD 0.9383773149191051\n",
      "b: SUGGESTION VALUE 2.4159930334616626\n",
      "c: ITEMS ['tote', 'tot', 'leiche', 'schlecht', 'sarg', 'panisch']\n",
      "c: AVG SIMILARITY 0.17701964937150477\n",
      "c: MEAN VALENCE -2.3749999999999996\n",
      "c: MEAN VALENCE STD 0.7569388585214444\n",
      "c: MEAN AROUSAL 4.080999066293184\n",
      "c: MEAN AROUSAL STD 0.88612557315004\n",
      "c: SUGGESTION VALUE 2.4055799423878432\n",
      "d: ITEMS ['alptraum', 'angst', 'furcht', 'einsam']\n",
      "d: AVG SIMILARITY 0.28125645716985065\n",
      "d: MEAN VALENCE -2.45\n",
      "d: MEAN VALENCE STD 0.760118017140098\n",
      "d: MEAN AROUSAL 4.107854194309303\n",
      "d: MEAN AROUSAL STD 0.7886513453944881\n",
      "d: SUGGESTION VALUE 2.3959310934714155\n",
      "e: ITEMS ['tod', 'verlust', 'grausam', 'lüge', 'traurig', 'abschied']\n",
      "e: AVG SIMILARITY 0.22484410256147386\n",
      "e: MEAN VALENCE -2.252941176470588\n",
      "e: MEAN VALENCE STD 0.7596602883849339\n",
      "e: MEAN AROUSAL 3.5912698412698414\n",
      "e: MEAN AROUSAL STD 1.0092946033417556\n",
      "e: SUGGESTION VALUE 2.3024518100150857\n",
      "1 ['krieg', 'zerstören', 'strafe', 'streit', 'tragisch']\n",
      "2 ['töten', 'gift', 'waffe', 'stehlen']\n",
      "3 ['tote', 'tot', 'leiche', 'schlecht', 'sarg', 'panisch']\n",
      "4 ['alptraum', 'angst', 'furcht', 'einsam']\n",
      "5 ['tod', 'verlust', 'grausam', 'lüge', 'traurig', 'abschied']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = -2\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"PANEM_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] <= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"PANEM_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelPanem.key_to_index[word] for word in low_valence_words]\n",
    "valence_word_vectors = [modelPanem.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = low_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "    \n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_valence_words)[class_members])))\n",
    "    for member1 in np.array(low_valence_words)[class_members]:\n",
    "        for member2 in np.array(low_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelPanem.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "    \n",
    "low_val_Panem = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_val_Panem.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_val_Panem, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020b4a26",
   "metadata": {},
   "source": [
    "### 3. High Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c498bbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['dolch', 'sturm', 'scharf', 'panisch', 'waffe', 'schrei'], 1: ['lüge', 'macht', 'leid', 'krieg'], 4: ['wahnsinn', 'zorn', 'schmerz', 'schreck', 'angst', 'furcht', 'alptraum', 'panik'], 3: ['leiche', 'tot', 'tote', 'blutig'], 2: ['feind', 'gefahr', 'brutal']}\n",
      "a: ITEMS ['dolch', 'sturm', 'scharf', 'panisch', 'waffe', 'schrei']\n",
      "a: AVG SIMILARITY 0.18600574582815171\n",
      "a: MEAN VALENCE -1.2416666666666665\n",
      "a: MEAN VALENCE STD 0.994731168710067\n",
      "a: MEAN AROUSAL 4.189877471456419\n",
      "a: MEAN AROUSAL STD 0.8268151831207557\n",
      "a: SUGGESTION VALUE 4.756090600864469\n",
      "b: ITEMS ['lüge', 'macht', 'leid', 'krieg']\n",
      "b: AVG SIMILARITY 0.25238679101069766\n",
      "b: MEAN VALENCE -1.7294117647058824\n",
      "b: MEAN VALENCE STD 0.8925198492397692\n",
      "b: MEAN AROUSAL 4.235912698412699\n",
      "b: MEAN AROUSAL STD 0.745992807782174\n",
      "b: SUGGESTION VALUE 4.5487971609516675\n",
      "c: ITEMS ['feind', 'gefahr', 'brutal']\n",
      "c: AVG SIMILARITY 0.24656043946743011\n",
      "c: MEAN VALENCE -1.9823529411764707\n",
      "c: MEAN VALENCE STD 0.7779619537104682\n",
      "c: MEAN AROUSAL 4.352422723475356\n",
      "c: MEAN AROUSAL STD 0.8738014759221141\n",
      "c: SUGGESTION VALUE 4.312363450437306\n",
      "d: ITEMS ['leiche', 'tot', 'tote', 'blutig']\n",
      "d: AVG SIMILARITY 0.24404179056485495\n",
      "d: MEAN VALENCE -2.3375000000000004\n",
      "d: MEAN VALENCE STD 0.7745901371950252\n",
      "d: MEAN AROUSAL 4.208998599439775\n",
      "d: MEAN AROUSAL STD 0.8512787309122878\n",
      "d: SUGGESTION VALUE 4.377963807637112\n",
      "e: ITEMS ['wahnsinn', 'zorn', 'schmerz', 'schreck', 'angst', 'furcht', 'alptraum', 'panik']\n",
      "e: AVG SIMILARITY 0.31327996935163227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: MEAN VALENCE -2.0294117647058827\n",
      "e: MEAN VALENCE STD 0.94953506810292\n",
      "e: MEAN AROUSAL 4.30905695611578\n",
      "e: MEAN AROUSAL STD 0.7102294743680319\n",
      "e: SUGGESTION VALUE 5.7799644503145355\n",
      "1 ['wahnsinn', 'zorn', 'schmerz', 'schreck', 'angst', 'furcht', 'alptraum', 'panik']\n",
      "2 ['dolch', 'sturm', 'scharf', 'panisch', 'waffe', 'schrei']\n",
      "3 ['lüge', 'macht', 'leid', 'krieg']\n",
      "4 ['leiche', 'tot', 'tote', 'blutig']\n",
      "5 ['feind', 'gefahr', 'brutal']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"PANEM_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] >= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "top_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"PANEM_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelPanem.key_to_index[word] for word in high_arousal_words]\n",
    "arousal_word_vectors = [modelPanem.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = high_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_arousal_words)[class_members])))\n",
    "    for member1 in np.array(high_arousal_words)[class_members]:\n",
    "        for member2 in np.array(high_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelPanem.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + sum(arousal_means) / len(arousal_means) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(high_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "\n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_arousal_Panem = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_arousal_Panem.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_arousal_Panem, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c230c80",
   "metadata": {},
   "source": [
    "### 4. Low Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47e67745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['schlaf', 'weich', 'friede', 'ding', 'decke', 'teller', 'sofa', 'kissen'], 0: ['still', 'pause', 'wenig'], 1: ['wiese', 'baum', 'boden', 'gras', 'sand'], 4: ['zaghaft', 'stumm', 'gesund', 'wange'], 2: ['garten', 'himmel', 'herbst', 'schlicht', 'zimmer']}\n",
      "a: ITEMS ['still', 'pause', 'wenig']\n",
      "a: AVG SIMILARITY 0.22753689686457315\n",
      "a: MEAN VALENCE 0.2833333333333333\n",
      "a: MEAN VALENCE STD 0.9889026933333334\n",
      "a: MEAN AROUSAL 1.390142021720969\n",
      "a: MEAN AROUSAL STD 0.6106310947327894\n",
      "a: SUGGESTION VALUE 2.57775742129807\n",
      "b: ITEMS ['wiese', 'baum', 'boden', 'gras', 'sand']\n",
      "b: AVG SIMILARITY 0.3421886444091797\n",
      "b: MEAN VALENCE 1.1092941176470588\n",
      "b: MEAN VALENCE STD 1.107478975479675\n",
      "b: MEAN AROUSAL 1.5447973856209152\n",
      "b: MEAN AROUSAL STD 0.7026595629208274\n",
      "b: SUGGESTION VALUE 2.6734674418199678\n",
      "c: ITEMS ['garten', 'himmel', 'herbst', 'schlicht', 'zimmer']\n",
      "c: AVG SIMILARITY 0.20147554911673068\n",
      "c: MEAN VALENCE 1.24\n",
      "c: MEAN VALENCE STD 0.8025731934745244\n",
      "c: MEAN AROUSAL 1.648888888888889\n",
      "c: MEAN AROUSAL STD 0.7439103291499225\n",
      "c: SUGGESTION VALUE 2.3083802538848945\n",
      "d: ITEMS ['schlaf', 'weich', 'friede', 'ding', 'decke', 'teller', 'sofa', 'kissen']\n",
      "d: AVG SIMILARITY 0.18958642932453326\n",
      "d: MEAN VALENCE 1.3088235294117647\n",
      "d: MEAN VALENCE STD 0.9719312471211247\n",
      "d: MEAN AROUSAL 1.4834262125902993\n",
      "d: MEAN AROUSAL STD 0.7271569288247138\n",
      "d: SUGGESTION VALUE 2.9238891809983745\n",
      "e: ITEMS ['zaghaft', 'stumm', 'gesund', 'wange']\n",
      "e: AVG SIMILARITY 0.1619298344788452\n",
      "e: MEAN VALENCE 0.55\n",
      "e: MEAN VALENCE STD 0.6533771875000001\n",
      "e: MEAN AROUSAL 1.574561403508772\n",
      "e: MEAN AROUSAL STD 0.8333290086065596\n",
      "e: SUGGESTION VALUE 2.132045880629241\n",
      "1 ['schlaf', 'weich', 'friede', 'ding', 'decke', 'teller', 'sofa', 'kissen']\n",
      "2 ['wiese', 'baum', 'boden', 'gras', 'sand']\n",
      "3 ['still', 'pause', 'wenig']\n",
      "4 ['garten', 'himmel', 'herbst', 'schlicht', 'zimmer']\n",
      "5 ['zaghaft', 'stumm', 'gesund', 'wange']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"PANEM_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] <= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"PANEM_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelPanem.key_to_index[word] for word in low_arousal_words]\n",
    "arousal_word_vectors = [modelPanem.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = low_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_arousal_words)[class_members])))\n",
    "    for member1 in np.array(low_arousal_words)[class_members]:\n",
    "        for member2 in np.array(low_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelPanem.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + (4 - sum(arousal_means) / len(arousal_means)) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(low_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "low_arousal_Panem = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_arousal_Panem.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_arousal_Panem, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedcd6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e7196c2",
   "metadata": {},
   "source": [
    "## Originals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a11739",
   "metadata": {},
   "source": [
    "### 1. High Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f59cc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['lust', 'chance', 'spaß', 'glück'], 4: ['begeistern', 'lieb', 'ehrlich', 'mutig', 'freuen', 'leben', 'wahrheit', 'freund', 'lachen', 'lieben'], 2: ['luft', 'warm', 'vertrauen', 'gefühl', 'himmel'], 1: ['strahlen', 'lächeln'], 3: ['reise', 'geschenk', 'sommer', 'ferien']}\n",
      "a: ITEMS ['lust', 'chance', 'spaß', 'glück']\n",
      "a: AVG SIMILARITY 0.28434756646553677\n",
      "a: MEAN VALENCE 2.2852941176470587\n",
      "a: MEAN VALENCE STD 0.7373813269744321\n",
      "a: MEAN AROUSAL 3.338854489164087\n",
      "a: MEAN AROUSAL STD 1.2745497820177278\n",
      "a: SUGGESTION VALUE 2.22712391572867\n",
      "b: ITEMS ['strahlen', 'lächeln']\n",
      "b: AVG SIMILARITY 0.29622453451156616\n",
      "b: MEAN VALENCE 2.2470588235294118\n",
      "b: MEAN VALENCE STD 0.8307058321763818\n",
      "b: MEAN AROUSAL 2.4563492063492065\n",
      "b: MEAN AROUSAL STD 1.160151066972619\n",
      "b: SUGGESTION VALUE 1.8881167222657174\n",
      "c: ITEMS ['luft', 'warm', 'vertrauen', 'gefühl', 'himmel']\n",
      "c: AVG SIMILARITY 0.1610002614557743\n",
      "c: MEAN VALENCE 2.2123529411764706\n",
      "c: MEAN VALENCE STD 0.7756102190714588\n",
      "c: MEAN AROUSAL 2.535263157894737\n",
      "c: MEAN AROUSAL STD 1.073765208763273\n",
      "c: SUGGESTION VALUE 2.039169911532373\n",
      "d: ITEMS ['reise', 'geschenk', 'sommer', 'ferien']\n",
      "d: AVG SIMILARITY 0.2798289706309636\n",
      "d: MEAN VALENCE 2.4125\n",
      "d: MEAN VALENCE STD 0.6825724618012189\n",
      "d: MEAN AROUSAL 2.820261437908497\n",
      "d: MEAN AROUSAL STD 1.1731417699453799\n",
      "d: SUGGESTION VALUE 2.4428715974607353\n",
      "e: ITEMS ['begeistern', 'lieb', 'ehrlich', 'mutig', 'freuen', 'leben', 'wahrheit', 'freund', 'lachen', 'lieben']\n",
      "e: AVG SIMILARITY 0.19610172799891895\n",
      "e: MEAN VALENCE 2.3747058823529414\n",
      "e: MEAN VALENCE STD 0.7038420488547938\n",
      "e: MEAN AROUSAL 2.842000835421888\n",
      "e: MEAN AROUSAL STD 1.2085453011068021\n",
      "e: SUGGESTION VALUE 3.041090171501102\n",
      "1 ['begeistern', 'lieb', 'ehrlich', 'mutig', 'freuen', 'leben', 'wahrheit', 'freund', 'lachen', 'lieben']\n",
      "2 ['reise', 'geschenk', 'sommer', 'ferien']\n",
      "3 ['lust', 'chance', 'spaß', 'glück']\n",
      "4 ['luft', 'warm', 'vertrauen', 'gefühl', 'himmel']\n",
      "5 ['strahlen', 'lächeln']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = 2\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"POTTERORIGINALS_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] >= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "top_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"POTTERORIGINALS_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelPotterOriginals.key_to_index[word] for word in high_valence_words]\n",
    "valence_word_vectors = [modelPotterOriginals.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation on PCA\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = high_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "\n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_valence_words)[class_members])))\n",
    "    for member1 in np.array(high_valence_words)[class_members]:\n",
    "        for member2 in np.array(high_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelPotterOriginals.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))                        \n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_val_PotterOriginals = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_val_PotterOriginals.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_val_PotterOriginals, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90419cf",
   "metadata": {},
   "source": [
    "### 2. Low Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd673aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['mord', 'tod', 'zerstören', 'waffe', 'lüge', 'fluch', 'verlies', 'gefahr'], 0: ['töten', 'tot', 'zwingen', 'befehl', 'verletzen'], 1: ['angst', 'ärger', 'entsetzt'], 2: ['leiche', 'grab', 'stehlen', 'kerker'], 4: ['schlecht', 'traurig', 'schlimm', 'übel'], 5: ['schlagen']}\n",
      "a: ITEMS ['töten', 'tot', 'zwingen', 'befehl', 'verletzen']\n",
      "a: AVG SIMILARITY 0.22869802378118037\n",
      "a: MEAN VALENCE -2.2470588235294118\n",
      "a: MEAN VALENCE STD 0.8372256356877195\n",
      "a: MEAN AROUSAL 4.043333333333334\n",
      "a: MEAN AROUSAL STD 0.9863054651832167\n",
      "a: SUGGESTION VALUE 2.0912271749750584\n",
      "b: ITEMS ['angst', 'ärger', 'entsetzt']\n",
      "b: AVG SIMILARITY 0.2643798887729645\n",
      "b: MEAN VALENCE -2.1\n",
      "b: MEAN VALENCE STD 0.6330686329267002\n",
      "b: MEAN AROUSAL 3.9603174603174605\n",
      "b: MEAN AROUSAL STD 0.8562684097727241\n",
      "b: SUGGESTION VALUE 2.004209192549032\n",
      "c: ITEMS ['leiche', 'grab', 'stehlen', 'kerker']\n",
      "c: AVG SIMILARITY 0.22772920628388724\n",
      "c: MEAN VALENCE -2.2125\n",
      "c: MEAN VALENCE STD 0.7136672205871412\n",
      "c: MEAN AROUSAL 3.897642390289449\n",
      "c: MEAN AROUSAL STD 0.9945850024054199\n",
      "c: SUGGESTION VALUE 2.098646884626806\n",
      "d: ITEMS ['mord', 'tod', 'zerstören', 'waffe', 'lüge', 'fluch', 'verlies', 'gefahr']\n",
      "d: AVG SIMILARITY 0.23785989971033164\n",
      "d: MEAN VALENCE -2.3121323529411764\n",
      "d: MEAN VALENCE STD 0.6711855414531545\n",
      "d: MEAN AROUSAL 4.02470238095238\n",
      "d: MEAN AROUSAL STD 0.9906195165439043\n",
      "d: SUGGESTION VALUE 2.7758532032874337\n",
      "e: ITEMS ['schlecht', 'traurig', 'schlimm', 'übel']\n",
      "e: AVG SIMILARITY 0.269771804412206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: MEAN VALENCE -2.030882352941177\n",
      "e: MEAN VALENCE STD 0.7983870413209225\n",
      "e: MEAN AROUSAL 3.472222222222222\n",
      "e: MEAN AROUSAL STD 0.8546383679127187\n",
      "e: SUGGESTION VALUE 1.826015068706931\n",
      "f: ITEMS ['schlagen']\n",
      "f: MEAN VALENCE -1.9117647058823528\n",
      "f: MEAN VALENCE STD 0.9959812295548891\n",
      "f: MEAN AROUSAL 3.9444444444444446\n",
      "f: MEAN AROUSAL STD 0.8726040960806526\n",
      "f: SUGGESTION VALUE 0\n",
      "1 ['mord', 'tod', 'zerstören', 'waffe', 'lüge', 'fluch', 'verlies', 'gefahr']\n",
      "2 ['leiche', 'grab', 'stehlen', 'kerker']\n",
      "3 ['töten', 'tot', 'zwingen', 'befehl', 'verletzen']\n",
      "4 ['angst', 'ärger', 'entsetzt']\n",
      "5 ['schlecht', 'traurig', 'schlimm', 'übel']\n",
      "6 ['schlagen']\n"
     ]
    }
   ],
   "source": [
    "# Define relevant valence words by threshold value\n",
    "\n",
    "emo_mean = -2\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"POTTERORIGINALS_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] <= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant valence words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"POTTERORIGINALS_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for valence words\n",
    "\n",
    "valence_words_index = [modelPotterOriginals.key_to_index[word] for word in low_valence_words]\n",
    "valence_word_vectors = [modelPotterOriginals.get_vector(i) for i in valence_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = low_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "    \n",
    "print(valence_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_valence_words)[class_members])))\n",
    "    for member1 in np.array(low_valence_words)[class_members]:\n",
    "        for member2 in np.array(low_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelPotterOriginals.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "    \n",
    "low_val_PotterOriginals = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_val_PotterOriginals.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_val_PotterOriginals, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49991ed",
   "metadata": {},
   "source": [
    "### 3. High Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a15b015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['zwingen', 'opfer', 'angriff', 'kampf', 'macht', 'waffe', 'gefahr', 'mord'], 3: ['verraten', 'lüge', 'scharf'], 1: ['drängen', 'schlagen'], 2: ['ärger', 'warnen', 'leid'], 4: ['kerker', 'leiche', 'tot'], 5: ['zorn', 'schreck', 'schmerz', 'angst', 'schrei', 'panik']}\n",
      "a: ITEMS ['zwingen', 'opfer', 'angriff', 'kampf', 'macht', 'waffe', 'gefahr', 'mord']\n",
      "a: AVG SIMILARITY 0.29268886388412546\n",
      "a: MEAN VALENCE -1.8297794117647062\n",
      "a: MEAN VALENCE STD 0.9769039745112281\n",
      "a: MEAN AROUSAL 4.124900793650793\n",
      "a: MEAN AROUSAL STD 0.8269579190128641\n",
      "a: SUGGESTION VALUE 5.304998408721197\n",
      "b: ITEMS ['drängen', 'schlagen']\n",
      "b: AVG SIMILARITY 0.20976389944553375\n",
      "b: MEAN VALENCE -1.6176470588235294\n",
      "b: MEAN VALENCE STD 1.001321764210206\n",
      "b: MEAN AROUSAL 3.938888888888889\n",
      "b: MEAN AROUSAL STD 0.9264345658938871\n",
      "b: SUGGESTION VALUE 3.552495590240691\n",
      "c: ITEMS ['ärger', 'warnen', 'leid']\n",
      "c: AVG SIMILARITY 0.24544737239678702\n",
      "c: MEAN VALENCE -1.3666666666666665\n",
      "c: MEAN VALENCE STD 1.0149001794597508\n",
      "c: MEAN AROUSAL 4.037037037037037\n",
      "c: MEAN AROUSAL STD 0.8394066577638788\n",
      "c: SUGGESTION VALUE 3.985792882276921\n",
      "d: ITEMS ['verraten', 'lüge', 'scharf']\n",
      "d: AVG SIMILARITY 0.17276538908481598\n",
      "d: MEAN VALENCE -1.2549019607843135\n",
      "d: MEAN VALENCE STD 1.1272916171111476\n",
      "d: MEAN AROUSAL 4.016569200779727\n",
      "d: MEAN AROUSAL STD 0.7890042335236483\n",
      "d: SUGGESTION VALUE 3.9363074287591284\n",
      "e: ITEMS ['kerker', 'leiche', 'tot']\n",
      "e: AVG SIMILARITY 0.15365466848015785\n",
      "e: MEAN VALENCE -2.283333333333333\n",
      "e: MEAN VALENCE STD 0.8204654266666668\n",
      "e: MEAN AROUSAL 4.1227824463118585\n",
      "e: MEAN AROUSAL STD 0.9144858508211468\n",
      "e: SUGGESTION VALUE 3.891878831954278\n",
      "f: ITEMS ['zorn', 'schreck', 'schmerz', 'angst', 'schrei', 'panik']\n",
      "f: AVG SIMILARITY 0.31855584184328717\n",
      "f: MEAN VALENCE -1.8558823529411768\n",
      "f: MEAN VALENCE STD 1.0875882605786287\n",
      "f: MEAN AROUSAL 4.30532212885154\n",
      "f: MEAN AROUSAL STD 0.7444462684696957\n",
      "f: SUGGESTION VALUE 5.198809512254324\n",
      "1 ['zwingen', 'opfer', 'angriff', 'kampf', 'macht', 'waffe', 'gefahr', 'mord']\n",
      "2 ['zorn', 'schreck', 'schmerz', 'angst', 'schrei', 'panik']\n",
      "3 ['ärger', 'warnen', 'leid']\n",
      "4 ['verraten', 'lüge', 'scharf']\n",
      "5 ['kerker', 'leiche', 'tot']\n",
      "6 ['drängen', 'schlagen']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"POTTERORIGINALS_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] >= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "top_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"POTTERORIGINALS_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[-top_n:]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelPotterOriginals.key_to_index[word] for word in high_arousal_words]\n",
    "arousal_word_vectors = [modelPotterOriginals.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = high_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_arousal_words)[class_members])))\n",
    "    for member1 in np.array(high_arousal_words)[class_members]:\n",
    "        for member2 in np.array(high_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelPotterOriginals.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + sum(arousal_means) / len(arousal_means) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(high_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "\n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "high_arousal_PotterOriginals = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_arousal_PotterOriginals.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_arousal_PotterOriginals, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e30522",
   "metadata": {},
   "source": [
    "### 4. Low Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1d3abf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: ['schlaf', 'kamin', 'teller', 'kissen', 'zimmer', 'tisch', 'sessel'], 3: ['pause', 'stumm', 'schweigen'], 0: ['schale', 'ding', 'feder', 'becher', 'glas', 'hand', 'uhr'], 2: ['baum', 'boden', 'gras', 'decke', 'garten', 'himmel', 'wange'], 1: ['wenig']}\n",
      "a: ITEMS ['schale', 'ding', 'feder', 'becher', 'glas', 'hand', 'uhr']\n",
      "a: AVG SIMILARITY 0.2106831180197852\n",
      "a: MEAN VALENCE 0.6292436974789916\n",
      "a: MEAN VALENCE STD 0.9465792071813844\n",
      "a: MEAN AROUSAL 1.678206229860365\n",
      "a: MEAN AROUSAL STD 0.8190312862461895\n",
      "a: SUGGESTION VALUE 2.4109900306506002\n",
      "b: ITEMS ['wenig']\n",
      "b: MEAN VALENCE -0.9\n",
      "b: MEAN VALENCE STD 0.99\n",
      "b: MEAN AROUSAL 1.5263157894736843\n",
      "b: MEAN AROUSAL STD 0.7723284457212328\n",
      "b: SUGGESTION VALUE 0\n",
      "c: ITEMS ['baum', 'boden', 'gras', 'decke', 'garten', 'himmel', 'wange']\n",
      "c: AVG SIMILARITY 0.24257203865618931\n",
      "c: MEAN VALENCE 1.2757142857142856\n",
      "c: MEAN VALENCE STD 1.028023331091998\n",
      "c: MEAN AROUSAL 1.5947619047619046\n",
      "c: MEAN AROUSAL STD 0.7495403739693831\n",
      "c: SUGGESTION VALUE 2.671056181505908\n",
      "d: ITEMS ['pause', 'stumm', 'schweigen']\n",
      "d: AVG SIMILARITY 0.2262851893901825\n",
      "d: MEAN VALENCE -0.004901960784313764\n",
      "d: MEAN VALENCE STD 1.288015205294083\n",
      "d: MEAN AROUSAL 1.5468671679197996\n",
      "d: MEAN AROUSAL STD 0.8140508327897891\n",
      "d: SUGGESTION VALUE 2.1593956917963726\n",
      "e: ITEMS ['schlaf', 'kamin', 'teller', 'kissen', 'zimmer', 'tisch', 'sessel']\n",
      "e: AVG SIMILARITY 0.26666350095045\n",
      "e: MEAN VALENCE 1.2485714285714284\n",
      "e: MEAN VALENCE STD 0.946297558001679\n",
      "e: MEAN AROUSAL 1.5795380608383707\n",
      "e: MEAN AROUSAL STD 0.7484715792922325\n",
      "e: SUGGESTION VALUE 2.727880666943778\n",
      "1 ['schlaf', 'kamin', 'teller', 'kissen', 'zimmer', 'tisch', 'sessel']\n",
      "2 ['baum', 'boden', 'gras', 'decke', 'garten', 'himmel', 'wange']\n",
      "3 ['schale', 'ding', 'feder', 'becher', 'glas', 'hand', 'uhr']\n",
      "4 ['pause', 'stumm', 'schweigen']\n",
      "5 ['wenig']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define relevant arousal words by threshold value\n",
    "\n",
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"POTTERORIGINALS_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] <= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])\n",
    "\n",
    "# Define relevant arousal words by ranking\n",
    "\n",
    "bot_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"POTTERORIGINALS_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[:bot_n]\n",
    "\n",
    "# Get vectors for arousal words\n",
    "\n",
    "arousal_words_index = [modelPotterOriginals.key_to_index[word] for word in low_arousal_words]\n",
    "arousal_word_vectors = [modelPotterOriginals.get_vector(i) for i in arousal_words_index]\n",
    "\n",
    "# Normalize vectors on unit circle\n",
    "\n",
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))\n",
    "\n",
    "# Cluster with Affinity Propagation\n",
    "\n",
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)\n",
    "\n",
    "# Tranform cluster to dictionary\n",
    "\n",
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = low_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)\n",
    "\n",
    "# Print relevant information of clusters\n",
    "\n",
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_arousal_words)[class_members])))\n",
    "    for member1 in np.array(low_arousal_words)[class_members]:\n",
    "        for member2 in np.array(low_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(modelPotterOriginals.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + (4 - sum(arousal_means) / len(arousal_means)) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(low_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))\n",
    "    \n",
    "# Ranking for suggestion values\n",
    "\n",
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))\n",
    "\n",
    "low_arousal_PotterOriginals = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_arousal_PotterOriginals.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_arousal_PotterOriginals, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
